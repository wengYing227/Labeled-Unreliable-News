{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyI5SA6HIoRH"
   },
   "source": [
    "# CS4248 Project\n",
    "(DON'T CLICK RUN ALL! Lemmatization takes tooo long and pls don't run it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS033yHSHyAx",
    "outputId": "e923c9e4-6bda-4a5a-970a-3bdd5ee92c59",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:44.741076Z",
     "start_time": "2024-04-13T10:53:43.518239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: nltk==3.8.1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 1)) (3.8.1)\r\n",
      "Requirement already satisfied: numpy==1.25.1 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (1.25.1)\r\n",
      "Requirement already satisfied: pandas==2.1.1 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (2.1.1)\r\n",
      "Requirement already satisfied: pyspellchecker==0.8.1 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (0.8.1)\r\n",
      "Requirement already satisfied: scikit-learn==1.4.1.post1 in /Library/Python/3.9/site-packages (from -r requirements.txt (line 5)) (1.4.1.post1)\r\n",
      "Requirement already satisfied: tqdm==4.65.0 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (4.65.0)\r\n",
      "Requirement already satisfied: textblob in /Users/stella/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (0.18.0.post0)\r\n",
      "Requirement already satisfied: click in /Users/stella/Library/Python/3.9/lib/python/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (8.1.5)\r\n",
      "Requirement already satisfied: joblib in /Library/Python/3.9/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Python/3.9/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (2023.12.25)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2023.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/stella/Library/Python/3.9/lib/python/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2.8.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Python/3.9/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Python/3.9/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (1.12.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas==2.1.1->-r requirements.txt (line 3)) (1.15.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\r\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# \n",
    "# %cd \"/content/drive/My Drive/CS4248 Project\"\n",
    "# !cd \"/content/drive/My Drive/CS4248 Project\"\n",
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "2nqSeqYQJ4vW",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:45.292003Z",
     "start_time": "2024-04-13T10:53:45.076294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stella/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9PepPt_CL94x",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:48.743774Z",
     "start_time": "2024-04-13T10:53:47.812551Z"
    }
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(999999)\n",
    "train = pd.read_csv('raw_data/fulltrain.csv', header = None, names=['class','text'])\n",
    "X_train = train['text']\n",
    "y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sCT1xI_yXFJO",
    "outputId": "172bcde2-37a1-40c2-e329-f0152f49ab50",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:48.749928Z",
     "start_time": "2024-04-13T10:53:48.745326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   class                                               text\n0      1  A little less than a decade ago, hockey fans w...\n1      1  The writers of the HBO series The Sopranos too...\n2      1  Despite claims from the TV news outlet to offe...\n3      1  After receiving 'subpar' service and experienc...\n4      1  After watching his beloved Seattle Mariners pr...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A little less than a decade ago, hockey fans w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>The writers of the HBO series The Sopranos too...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Despite claims from the TV news outlet to offe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>After receiving 'subpar' service and experienc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>After watching his beloved Seattle Mariners pr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-FcMBozxWAvz",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:49.729757Z",
     "start_time": "2024-04-13T10:53:49.665073Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"raw_data/balancedtest.csv\", header = None, names=['class','text'])\n",
    "X_test = test['text']\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s5befmSMXN8N",
    "outputId": "c1aef16d-ccb9-4036-f8af-1a6c9d16c035",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:53:50.848922Z",
     "start_time": "2024-04-13T10:53:50.829320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   class                                               text\n0      1  When so many actors seem content to churn out ...\n1      1   In what football insiders are calling an unex...\n2      1  In a freak accident following Game 3 of the N....\n3      1  North Koreas official news agency announced to...\n4      1  The former Alaska Governor Sarah Palin would b...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When so many actors seem content to churn out ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>In what football insiders are calling an unex...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>In a freak accident following Game 3 of the N....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>North Koreas official news agency announced to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>The former Alaska Governor Sarah Palin would b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WOxbEhspgUT"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NKfM8O-nbbpJ",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:03.141683Z",
     "start_time": "2024-04-13T10:53:53.948092Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(X_train, X_test):\n",
    "\n",
    "  tfidf_baseline = TfidfVectorizer(ngram_range=(1,1), max_features = 10000)\n",
    "\n",
    "  X_train_tfidf = tfidf_baseline.fit_transform(X_train)\n",
    "\n",
    "  X_test_tfidf = tfidf_baseline.transform(X_test)\n",
    "\n",
    "  return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITNfwpWkt1OI"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6Yrnd2f_y5W"
   },
   "source": [
    "### Lemmatization with POS Tagging\n",
    "(DON'T RUN AGAIN! It takes tooooo long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E3t6cQp1r-N",
    "outputId": "45aad408-e2fc-4eea-d48b-c4cd161199bd",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:09.908977Z",
     "start_time": "2024-04-13T10:54:09.888003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/stella/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# # WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "# \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# \n",
    "# # Define function to lemmatize each word with its POS tag\n",
    "# \n",
    "# # POS_TAGGER_FUNCTION : TYPE 1\n",
    "# def pos_tagger(nltk_tag):\n",
    "#     if nltk_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif nltk_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif nltk_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif nltk_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return None\n",
    "# \n",
    "# def lemmatize_with_pos(tokens):\n",
    "#   # tokenize the sentence and find the POS tag for each token\n",
    "#   pos_tagged = nltk.pos_tag(tokens)\n",
    "# \n",
    "#   # print(pos_tagged)\n",
    "# \n",
    "#   wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "#   # print(wordnet_tagged)\n",
    "# \n",
    "#   lemmatized_sentence = []\n",
    "#   for word, tag in wordnet_tagged:\n",
    "#       if tag is None:\n",
    "#           # if there is no available tag, append the token as is\n",
    "#           lemmatized_sentence.append(word)\n",
    "#       else:\n",
    "#           # else use the tag to lemmatize the token\n",
    "#           lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "#   # lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "# \n",
    "#   # print(lemmatized_sentence)\n",
    "#   return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-3cE9Qzt3zY",
    "outputId": "dd07285c-1ccd-41b5-c9d3-78d8174a7cb1",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:12.717251Z",
     "start_time": "2024-04-13T10:54:12.645805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# # Start preprocessing\n",
    "# \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "from spellchecker import SpellChecker\n",
    "# \n",
    "# punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "# \n",
    "# spell = SpellChecker()\n",
    "# \n",
    "# def preprocessing(data):\n",
    "#   data_clean = []\n",
    "#   for sentence in tqdm(data):\n",
    "# \n",
    "#     # Tokenization\n",
    "#     tokens = word_tokenize(sentence)\n",
    "# \n",
    "#     # Remove punctuation and number\n",
    "#     tokens = [w for w in tokens if (not w in punc) and (not w.isdigit())]\n",
    "# \n",
    "#     # Spell check\n",
    "#     # Taking too long time for each sentence, not practical to be used\n",
    "#     # tokens = [spell.correction(w) for w in tokens]\n",
    "#     # tokens = [w for w in tokens if w is not None and len(w) > 0]\n",
    "# \n",
    "#     # Lemmatization based on tagging\n",
    "#     tokens = lemmatize_with_pos(tokens)\n",
    "# \n",
    "#     data_clean.append((' ').join(tokens))\n",
    "#   return data_clean\n",
    "# \n",
    "# X_train_clean = preprocessing(X_train)\n",
    "# X_test_clean = preprocessing(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:13.529346Z",
     "start_time": "2024-04-13T10:54:13.516824Z"
    }
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import pandas as pd\n",
    "# \n",
    "# def write_to_csv(X_train_clean, X_test_clean):\n",
    "#     with open('raw_data/X_train_clean.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         for doc in X_train_clean:\n",
    "#             writer.writerow([doc])\n",
    "# \n",
    "#     with open('raw_data/X_test_clean.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         for doc in X_test_clean:\n",
    "#             writer.writerow([doc])\n",
    "# \n",
    "# # Uncomment if you want to save X_train_clean and X_test_clean\n",
    "# # write_to_csv(X_train_clean, X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:15.821822Z",
     "start_time": "2024-04-13T10:54:14.849919Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_from_file():\n",
    "    a_df = pd.read_csv('raw_data/X_train_clean.csv', header=None, dtype=str)\n",
    "    a = a_df[0].values\n",
    "    \n",
    "    b_df = pd.read_csv('raw_data/X_test_clean.csv', header=None, dtype=str)\n",
    "    b = b_df[0].values\n",
    "    return a, b\n",
    "\n",
    "# Uncomment if you want to read from file\n",
    "a, b = read_from_file()\n",
    "X_train_clean, X_test_clean = a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nH-JuFWdzqHa",
    "outputId": "1e641367-5188-4e56-8a83-b04dbde46ec0",
    "ExecuteTime": {
     "end_time": "2024-04-13T10:54:26.661145Z",
     "start_time": "2024-04-13T10:54:17.946992Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_clean_tfidf, X_test_clean_tfidf = tfidf(X_train_clean, X_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Embeddings\n",
    "#### GloVe\n",
    "- Download from https://nlp.stanford.edu/projects/glove/\n",
    "- Used Wikipedia 2014 + Gigaword 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file_path):\n",
    "    glove_model = {}\n",
    "    with open(glove_file_path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            # embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            try:\n",
    "                coefs = np.asarray(split_line[1:], dtype='float32')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            glove_model[word] = coefs\n",
    "    return glove_model\n",
    "\n",
    "glove_model = load_glove_model(\"glove.6B/glove.6B.300d.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T10:56:54.295316Z",
     "start_time": "2024-04-13T10:56:43.477622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "X_train_processed = X_train.apply(preprocess_text)\n",
    "X_test_processed = X_test.apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T10:58:41.037678Z",
     "start_time": "2024-04-13T10:57:13.798876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def document_vector(doc, model):\n",
    "    # Filter out words that are not in the embedding\n",
    "    embeddings = [model[word] for word in doc if word in model]\n",
    "    if not embeddings:\n",
    "        # If no words in the document are in the model, return a vector of zeros\n",
    "        return np.zeros(next(iter(model.values())).shape)\n",
    "    # Average the embeddings\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "X_train_vectors = np.array([document_vector(doc, glove_model) for doc in X_train_processed])\n",
    "X_test_vectors = np.array([document_vector(doc, glove_model) for doc in X_test_processed])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T10:58:53.335132Z",
     "start_time": "2024-04-13T10:58:41.039392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# TODO!: delete\n",
    "# def text_to_features(tokens, glove_model):\n",
    "#     vectors = [glove_model[token] for token in tokens if token in glove_model]\n",
    "#     if vectors:\n",
    "#         return np.mean(vectors, axis=0) # Return the mean of the vectors\n",
    "#     else:\n",
    "#         return np.zeros(300)  # Return a zero vector if no words are found\n",
    "# \n",
    "# # Convert X_train_clean to a pandas Series\n",
    "# X_train_clean_series = pd.Series(X_train_clean)\n",
    "# # Convert text to features using a predefined function (e.g., using GloVe embeddings)\n",
    "# glove_embedding_features = X_train_clean_series.apply(lambda x: pd.Series(text_to_features(x, glove_model)))\n",
    "# glove_embedding_features.columns = [f'Feature_{i}' for i in range(300)]\n",
    "# \n",
    "# # Use the same function to convert X_test_clean to a pandas Series\n",
    "# X_test_clean_series = pd.Series(X_test_clean)\n",
    "# glove_embedding_features_test = X_test_clean_series.apply(lambda x: pd.Series(text_to_features(x, glove_model)))\n",
    "# glove_embedding_features_test.columns = [f'Feature_{i}' for i in range(300)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T10:58:53.337857Z",
     "start_time": "2024-04-13T10:58:53.335294Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def SVM(X_train, y_train, X_test, y_test):\n",
    "    le = LabelEncoder()\n",
    "    y_train_en = le.fit_transform(y_train)\n",
    "    y_test_en = le.transform(y_test)\n",
    "    model = svm.SVC(kernel='linear', class_weight='balanced', probability=True) # Best Model chosen by Grid Search\n",
    "    model.fit(X_train, y_train_en)\n",
    "    predictions_y = model.predict(X_test)\n",
    "    print(\"SVM Accuracy Score -> \", accuracy_score(predictions_y, y_test_en) * 100)\n",
    "    print(classification_report(y_test_en, predictions_y))\n",
    "    cm = confusion_matrix(y_test_en, predictions_y)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T11:55:52.143513Z",
     "start_time": "2024-04-13T11:55:52.140912Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Approach 1: tfidf "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]....*...*\n",
      "optimization finished, #iter = 7139\n",
      "obj = -789.401718, rho = 0.700044\n",
      "nSV = 2220, nBSV = 397\n",
      "Total nSV = 2220\n",
      "....*...*\n",
      "optimization finished, #iter = 7298\n",
      "obj = -795.939370, rho = 0.746327\n",
      "nSV = 2270, nBSV = 409\n",
      "Total nSV = 2270\n",
      "....*...*\n",
      "optimization finished, #iter = 7141\n",
      "obj = -787.459236, rho = 0.742474\n",
      "nSV = 2204, nBSV = 381\n",
      "Total nSV = 2204\n",
      "....*..*\n",
      "optimization finished, #iter = 6952\n",
      "obj = -790.666170, rho = 0.684879\n",
      "nSV = 2243, nBSV = 421\n",
      "Total nSV = 2243\n",
      "....*...*\n",
      "optimization finished, #iter = 7207\n",
      "obj = -806.421280, rho = 0.734366\n",
      "nSV = 2247, nBSV = 406\n",
      "Total nSV = 2247\n",
      ".....*...*\n",
      "optimization finished, #iter = 8148\n",
      "obj = -912.494670, rho = -0.746157\n",
      "nSV = 2491, nBSV = 853\n",
      "......*...*\n",
      "optimization finished, #iter = 9700\n",
      "obj = -1260.480464, rho = -0.322423\n",
      "nSV = 3845, nBSV = 1587\n",
      "Total nSV = 3845\n",
      "......*...*\n",
      "optimization finished, #iter = 9950\n",
      "obj = -1239.615416, rho = -0.348236\n",
      "nSV = 3873, nBSV = 1587\n",
      "Total nSV = 3873\n",
      "......*....*\n",
      "optimization finished, #iter = 10010\n",
      "obj = -1263.831190, rho = -0.345038\n",
      "nSV = 3878, nBSV = 1593\n",
      "Total nSV = 3878\n",
      "......*...*\n",
      "optimization finished, #iter = 9508\n",
      "obj = -1246.220093, rho = -0.348632\n",
      "nSV = 3842, nBSV = 1565\n",
      "Total nSV = 3842\n",
      "......*...*\n",
      "optimization finished, #iter = 9874\n",
      "obj = -1271.290466, rho = -0.321455\n",
      "nSV = 3914, nBSV = 1621\n",
      "Total nSV = 3914\n",
      ".......*....*\n",
      "optimization finished, #iter = 11473\n",
      "obj = -1449.595018, rho = 0.352887\n",
      "nSV = 4369, nBSV = 1303\n",
      ".......*.....*\n",
      "optimization finished, #iter = 12164\n",
      "obj = -1920.525694, rho = 0.903014\n",
      "nSV = 4266, nBSV = 1447\n",
      "Total nSV = 4266\n",
      ".......*.....*\n",
      "optimization finished, #iter = 12469\n",
      "obj = -1912.223549, rho = 0.880364\n",
      "nSV = 4273, nBSV = 1439\n",
      "Total nSV = 4273\n",
      ".......*....*\n",
      "optimization finished, #iter = 11979\n",
      "obj = -1930.196435, rho = 0.909761\n",
      "nSV = 4268, nBSV = 1435\n",
      "Total nSV = 4268\n",
      ".......*.....*\n",
      "optimization finished, #iter = 12168\n",
      "obj = -1906.290162, rho = 0.928364\n",
      "nSV = 4254, nBSV = 1453\n",
      "Total nSV = 4254\n",
      ".......*.....*\n",
      "optimization finished, #iter = 12211\n",
      "obj = -1914.659467, rho = 0.928193\n",
      "nSV = 4244, nBSV = 1396\n",
      "Total nSV = 4244\n",
      ".........*.....*\n",
      "optimization finished, #iter = 14183\n",
      "obj = -2248.823733, rho = -0.948435\n",
      "nSV = 4831, nBSV = 2053\n",
      "....*...*\n",
      "optimization finished, #iter = 7625\n",
      "obj = -1052.015509, rho = -0.736993\n",
      "nSV = 2777, nBSV = 1169\n",
      "Total nSV = 2777\n",
      "....*...*\n",
      "optimization finished, #iter = 7543\n",
      "obj = -1026.081033, rho = -0.726072\n",
      "nSV = 2745, nBSV = 1133\n",
      "Total nSV = 2745\n",
      "....*...*\n",
      "optimization finished, #iter = 7607\n",
      "obj = -1036.705602, rho = -0.702332\n",
      "nSV = 2755, nBSV = 1168\n",
      "Total nSV = 2755\n",
      "....*...*\n",
      "optimization finished, #iter = 7561\n",
      "obj = -1028.620879, rho = -0.726637\n",
      "nSV = 2729, nBSV = 1169\n",
      "Total nSV = 2729\n",
      "....*...*\n",
      "optimization finished, #iter = 7607\n",
      "obj = -1045.744219, rho = -0.703227\n",
      "nSV = 2788, nBSV = 1182\n",
      "Total nSV = 2788\n",
      ".....*...*\n",
      "optimization finished, #iter = 8624\n",
      "obj = -1204.272410, rho = 0.758154\n",
      "nSV = 3088, nBSV = 1044\n",
      "...*..*\n",
      "optimization finished, #iter = 5394\n",
      "obj = -592.068028, rho = -0.129869\n",
      "nSV = 1693, nBSV = 317\n",
      "Total nSV = 1693\n",
      "...*..*\n",
      "optimization finished, #iter = 5468\n",
      "obj = -577.884889, rho = -0.115914\n",
      "nSV = 1672, nBSV = 296\n",
      "Total nSV = 1672\n",
      "...*..*\n",
      "optimization finished, #iter = 5455\n",
      "obj = -578.745744, rho = -0.150470\n",
      "nSV = 1698, nBSV = 297\n",
      "Total nSV = 1698\n",
      "...*..*\n",
      "optimization finished, #iter = 5669\n",
      "obj = -579.841640, rho = -0.135997\n",
      "nSV = 1679, nBSV = 294\n",
      "Total nSV = 1679\n",
      "...*..*\n",
      "optimization finished, #iter = 5531\n",
      "obj = -574.236095, rho = -0.153088\n",
      "nSV = 1687, nBSV = 289\n",
      "Total nSV = 1687\n",
      "....*..*\n",
      "optimization finished, #iter = 6325\n",
      "obj = -663.013234, rho = 0.146435\n",
      "nSV = 1861, nBSV = 185\n",
      ".....*...*\n",
      "optimization finished, #iter = 8709\n",
      "obj = -1311.848326, rho = 0.510898\n",
      "nSV = 3549, nBSV = 1184\n",
      "Total nSV = 3549\n",
      "......*...*\n",
      "optimization finished, #iter = 9576\n",
      "obj = -1319.211662, rho = 0.529371\n",
      "nSV = 3622, nBSV = 1143\n",
      "Total nSV = 3622\n",
      ".....*....*\n",
      "optimization finished, #iter = 9095\n",
      "obj = -1326.739217, rho = 0.529665\n",
      "nSV = 3600, nBSV = 1129\n",
      "Total nSV = 3600\n",
      "......*...*\n",
      "optimization finished, #iter = 9041\n",
      "obj = -1323.866607, rho = 0.515152\n",
      "nSV = 3617, nBSV = 1145\n",
      "Total nSV = 3617\n",
      ".....*....*\n",
      "optimization finished, #iter = 9113\n",
      "obj = -1324.522933, rho = 0.505550\n",
      "nSV = 3605, nBSV = 1130\n",
      "Total nSV = 3605\n",
      "......*....*\n",
      "optimization finished, #iter = 10394\n",
      "obj = -1529.795704, rho = -0.538252\n",
      "nSV = 4065, nBSV = 1873\n",
      "Total nSV = 13414\n",
      "SVM Accuracy Score ->  74.06666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82       750\n",
      "           1       0.81      0.48      0.60       750\n",
      "           2       0.60      0.77      0.67       750\n",
      "           3       0.77      0.93      0.84       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.76      0.74      0.73      3000\n",
      "weighted avg       0.76      0.74      0.73      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[586  72  49  43]\n",
      " [ 42 360 310  38]\n",
      " [ 33  10 575 132]\n",
      " [ 25   2  22 701]]\n"
     ]
    }
   ],
   "source": [
    "_ = SVM(X_train_clean_tfidf, y_train, X_test_clean_tfidf, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:01:00.060916Z",
     "start_time": "2024-04-09T19:06:18.961390Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Approach 2: word embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].....*..*.*\n",
      "optimization finished, #iter = 8662\n",
      "obj = -2071.714389, rho = 9.103812\n",
      "nSV = 2230, nBSV = 1857\n",
      "Total nSV = 2230\n",
      ".....*...*..*\n",
      "optimization finished, #iter = 9492\n",
      "obj = -2081.898901, rho = 8.840646\n",
      "nSV = 2247, nBSV = 1510\n",
      "Total nSV = 2247\n",
      ".....*..*\n",
      "optimization finished, #iter = 7056\n",
      "obj = -2074.884539, rho = 9.583814\n",
      "nSV = 2240, nBSV = 1522\n",
      "Total nSV = 2240\n",
      "....*..*\n",
      "optimization finished, #iter = 6744\n",
      "obj = -2071.024865, rho = 9.061015\n",
      "nSV = 2237, nBSV = 1889\n",
      "Total nSV = 2237\n",
      "....*.*.*\n",
      "optimization finished, #iter = 5761\n",
      "obj = -2056.512079, rho = 9.249406\n",
      "nSV = 2209, nBSV = 1884\n",
      "Total nSV = 2209\n",
      ".....*...*.*\n",
      "optimization finished, #iter = 8269\n",
      "obj = -2500.837423, rho = -9.375802\n",
      "nSV = 2647, nBSV = 2043\n",
      ".........*...*.....*\n",
      "optimization finished, #iter = 17350\n",
      "obj = -2197.209990, rho = -0.483711\n",
      "nSV = 3415, nBSV = 2642\n",
      "Total nSV = 3415\n",
      ".......*...*.....*\n",
      "optimization finished, #iter = 15184\n",
      "obj = -2159.869950, rho = -0.647812\n",
      "nSV = 3372, nBSV = 2576\n",
      "Total nSV = 3372\n",
      ".........*....*......*.*\n",
      "optimization finished, #iter = 19707\n",
      "obj = -2124.022028, rho = -0.654449\n",
      "nSV = 3346, nBSV = 2618\n",
      "Total nSV = 3346\n",
      "........*....*.....*\n",
      "optimization finished, #iter = 16816\n",
      "obj = -2150.452121, rho = -0.413373\n",
      "nSV = 3369, nBSV = 2666\n",
      "Total nSV = 3369\n",
      ".......*...*.....*.*\n",
      "optimization finished, #iter = 14590\n",
      "obj = -2158.708394, rho = -0.199315\n",
      "nSV = 3384, nBSV = 2691\n",
      "Total nSV = 3384\n",
      ".........*...*........*..*\n",
      "optimization finished, #iter = 21380\n",
      "obj = -2630.599162, rho = 0.584867\n",
      "nSV = 4027, nBSV = 3168\n",
      "........*...*.*\n",
      "optimization finished, #iter = 12118\n",
      "obj = -3655.309270, rho = 8.641718\n",
      "nSV = 4160, nBSV = 2661\n",
      "Total nSV = 4160\n",
      "........*....*......*..*\n",
      "optimization finished, #iter = 19548\n",
      "obj = -3741.905810, rho = 8.772012\n",
      "nSV = 4244, nBSV = 3069\n",
      "Total nSV = 4244\n",
      ".......*...*.*\n",
      "optimization finished, #iter = 11279\n",
      "obj = -3651.940680, rho = 8.380014\n",
      "nSV = 4149, nBSV = 3030\n",
      "Total nSV = 4149\n",
      "........*....*.....*.*\n",
      "optimization finished, #iter = 16941\n",
      "obj = -3740.533091, rho = 8.762207\n",
      "nSV = 4225, nBSV = 3217\n",
      "Total nSV = 4225\n",
      ".......*...*\n",
      "optimization finished, #iter = 10568\n",
      "obj = -3652.684657, rho = 8.815383\n",
      "nSV = 4145, nBSV = 3088\n",
      "Total nSV = 4145\n",
      ".........*....*.....*.*\n",
      "optimization finished, #iter = 18113\n",
      "obj = -4513.792609, rho = -8.716658\n",
      "nSV = 5067, nBSV = 3504\n",
      "........*...*......*...*\n",
      "optimization finished, #iter = 19384\n",
      "obj = -3299.213919, rho = -11.102638\n",
      "nSV = 3892, nBSV = 2894\n",
      "Total nSV = 3892\n",
      "........*...*........*....*\n",
      "optimization finished, #iter = 22272\n",
      "obj = -3281.528876, rho = -11.555283\n",
      "nSV = 3885, nBSV = 2953\n",
      "Total nSV = 3885\n",
      "........*..*.....*.*\n",
      "optimization finished, #iter = 14976\n",
      "obj = -3225.470775, rho = -11.044013\n",
      "nSV = 3820, nBSV = 2921\n",
      "Total nSV = 3820\n",
      "........*...*.....*.*\n",
      "optimization finished, #iter = 15761\n",
      "obj = -3238.320733, rho = -11.453127\n",
      "nSV = 3825, nBSV = 2758\n",
      "Total nSV = 3825\n",
      "........*...*......*.*\n",
      "optimization finished, #iter = 17041\n",
      "obj = -3199.793559, rho = -11.919452\n",
      "nSV = 3812, nBSV = 2811\n",
      "Total nSV = 3812\n",
      "Line search fails in two-class probability estimates\n",
      ".........*......*.........*.*\n",
      "optimization finished, #iter = 24620\n",
      "obj = -3978.191779, rho = 11.847658\n",
      "nSV = 4650, nBSV = 3350\n",
      "...*...*\n",
      "optimization finished, #iter = 6077\n",
      "obj = -1092.768206, rho = -0.308078\n",
      "nSV = 1066, nBSV = 842\n",
      "Total nSV = 1066\n",
      "..*..*\n",
      "optimization finished, #iter = 4348\n",
      "obj = -1033.059290, rho = -0.350491\n",
      "nSV = 1035, nBSV = 842\n",
      "Total nSV = 1035\n",
      "...*..*\n",
      "optimization finished, #iter = 5355\n",
      "obj = -1103.334382, rho = -0.391037\n",
      "nSV = 1076, nBSV = 839\n",
      "Total nSV = 1076\n",
      "...*.*\n",
      "optimization finished, #iter = 4687\n",
      "obj = -1035.879578, rho = -0.385636\n",
      "nSV = 1028, nBSV = 835\n",
      "Total nSV = 1028\n",
      "...*..*.*\n",
      "optimization finished, #iter = 5304\n",
      "obj = -1093.786637, rho = -1.422683\n",
      "nSV = 1069, nBSV = 832\n",
      "Total nSV = 1069\n",
      "....*...*...*\n",
      "optimization finished, #iter = 9137\n",
      "obj = -1274.914379, rho = 0.728557\n",
      "nSV = 1218, nBSV = 907\n",
      ".......*....*...*\n",
      "optimization finished, #iter = 13959\n",
      "obj = -1738.040621, rho = 4.704233\n",
      "nSV = 2503, nBSV = 1651\n",
      "Total nSV = 2503\n",
      "......*....*...*\n",
      "optimization finished, #iter = 12644\n",
      "obj = -1691.000738, rho = 5.191372\n",
      "nSV = 2443, nBSV = 1653\n",
      "Total nSV = 2443\n",
      "......*....*.....*\n",
      "optimization finished, #iter = 14794\n",
      "obj = -1690.606484, rho = 4.728972\n",
      "nSV = 2456, nBSV = 1636\n",
      "Total nSV = 2456\n",
      "......*...*....*\n",
      "optimization finished, #iter = 13757\n",
      "obj = -1706.330198, rho = 4.789813\n",
      "nSV = 2458, nBSV = 1624\n",
      "Total nSV = 2458\n",
      "......*....*....*\n",
      "optimization finished, #iter = 13786\n",
      "obj = -1722.109272, rho = 5.095488\n",
      "nSV = 2488, nBSV = 1629\n",
      "Total nSV = 2488\n",
      ".........*....*......*..*\n",
      "optimization finished, #iter = 19855\n",
      "obj = -2064.902690, rho = -5.133952\n",
      "nSV = 2924, nBSV = 2362\n",
      "Total nSV = 14728\n",
      "SVM Accuracy Score ->  64.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.64       750\n",
      "           1       0.64      0.61      0.63       750\n",
      "           2       0.54      0.54      0.54       750\n",
      "           3       0.67      0.86      0.75       750\n",
      "\n",
      "    accuracy                           0.64      3000\n",
      "   macro avg       0.65      0.64      0.64      3000\n",
      "weighted avg       0.65      0.64      0.64      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[425 228  72  25]\n",
      " [ 29 460 248  13]\n",
      " [ 54  10 402 284]\n",
      " [ 61  16  28 645]]\n"
     ]
    }
   ],
   "source": [
    "_ = SVM(X_train_vectors, y_train, X_test_vectors, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T11:08:18.987972Z",
     "start_time": "2024-04-13T10:58:53.341892Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: tfidf + word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].....*..*\n",
      "optimization finished, #iter = 7653\n",
      "obj = -528.536886, rho = 2.734790\n",
      "nSV = 1667, nBSV = 120\n",
      "Total nSV = 1667\n",
      ".....*...*\n",
      "optimization finished, #iter = 8246\n",
      "obj = -550.041230, rho = 2.935912\n",
      "nSV = 1684, nBSV = 194\n",
      "Total nSV = 1684\n",
      ".....*..*\n",
      "optimization finished, #iter = 7584\n",
      "obj = -523.319336, rho = 3.747095\n",
      "nSV = 1647, nBSV = 112\n",
      "Total nSV = 1647\n",
      ".....*...*\n",
      "optimization finished, #iter = 8059\n",
      "obj = -541.124638, rho = 3.047655\n",
      "nSV = 1741, nBSV = 148\n",
      "Total nSV = 1741\n",
      ".....*...*\n",
      "optimization finished, #iter = 8111\n",
      "obj = -526.220052, rho = 2.953224\n",
      "nSV = 1694, nBSV = 122\n",
      "Total nSV = 1694\n",
      "......*..*\n",
      "optimization finished, #iter = 8921\n",
      "obj = -620.553904, rho = -2.968800\n",
      "nSV = 1898, nBSV = 521\n",
      "........*....*\n",
      "optimization finished, #iter = 12196\n",
      "obj = -740.457620, rho = -1.682736\n",
      "nSV = 2510, nBSV = 859\n",
      "Total nSV = 2510\n",
      "........*....*\n",
      "optimization finished, #iter = 12033\n",
      "obj = -738.109092, rho = -1.563510\n",
      "nSV = 2498, nBSV = 836\n",
      "Total nSV = 2498\n",
      ".......*....*\n",
      "optimization finished, #iter = 11337\n",
      "obj = -730.615027, rho = -1.467939\n",
      "nSV = 2480, nBSV = 841\n",
      "Total nSV = 2480\n",
      "........*...*\n",
      "optimization finished, #iter = 11937\n",
      "obj = -731.777376, rho = -1.776010\n",
      "nSV = 2484, nBSV = 831\n",
      "Total nSV = 2484\n",
      "........*....*\n",
      "optimization finished, #iter = 12684\n",
      "obj = -736.900007, rho = -1.508764\n",
      "nSV = 2519, nBSV = 851\n",
      "Total nSV = 2519\n",
      ".........*.....*\n",
      "optimization finished, #iter = 14073\n",
      "obj = -864.244100, rho = 1.679111\n",
      "nSV = 2830, nBSV = 620\n",
      "........*...*\n",
      "optimization finished, #iter = 11696\n",
      "obj = -1136.991661, rho = 2.713153\n",
      "nSV = 2831, nBSV = 632\n",
      "Total nSV = 2831\n",
      "........*...*\n",
      "optimization finished, #iter = 11957\n",
      "obj = -1124.182902, rho = 2.724775\n",
      "nSV = 2834, nBSV = 687\n",
      "Total nSV = 2834\n",
      "........*....*\n",
      "optimization finished, #iter = 12027\n",
      "obj = -1110.536436, rho = 3.261267\n",
      "nSV = 2791, nBSV = 660\n",
      "Total nSV = 2791\n",
      "........*...*\n",
      "optimization finished, #iter = 11970\n",
      "obj = -1107.647576, rho = 2.736106\n",
      "nSV = 2839, nBSV = 727\n",
      "Total nSV = 2839\n",
      "........*....*\n",
      "optimization finished, #iter = 12544\n",
      "obj = -1116.723502, rho = 2.875076\n",
      "nSV = 2830, nBSV = 656\n",
      "Total nSV = 2830\n",
      "..........*....*\n",
      "optimization finished, #iter = 14446\n",
      "obj = -1323.107608, rho = -2.803156\n",
      "nSV = 3219, nBSV = 1138\n",
      "........*...*\n",
      "optimization finished, #iter = 11695\n",
      "obj = -717.491240, rho = -4.048732\n",
      "nSV = 2130, nBSV = 792\n",
      "Total nSV = 2130\n",
      ".......*...*\n",
      "optimization finished, #iter = 10563\n",
      "obj = -714.731916, rho = -4.281543\n",
      "nSV = 2104, nBSV = 776\n",
      "Total nSV = 2104\n",
      "......*....*\n",
      "optimization finished, #iter = 10598\n",
      "obj = -708.470793, rho = -4.222229\n",
      "nSV = 2086, nBSV = 746\n",
      "Total nSV = 2086\n",
      "......*....*\n",
      "optimization finished, #iter = 10406\n",
      "obj = -714.647227, rho = -4.406125\n",
      "nSV = 2104, nBSV = 791\n",
      "Total nSV = 2104\n",
      ".......*...*\n",
      "optimization finished, #iter = 10408\n",
      "obj = -715.308599, rho = -4.278377\n",
      "nSV = 2079, nBSV = 793\n",
      "Total nSV = 2079\n",
      "........*.....*..*\n",
      "optimization finished, #iter = 14313\n",
      "obj = -840.155491, rho = 4.295167\n",
      "nSV = 2370, nBSV = 578\n",
      "...*.*\n",
      "optimization finished, #iter = 4976\n",
      "obj = -276.973045, rho = -0.237885\n",
      "nSV = 1063, nBSV = 92\n",
      "Total nSV = 1063\n",
      "...*.*\n",
      "optimization finished, #iter = 4600\n",
      "obj = -261.392983, rho = -0.011123\n",
      "nSV = 1043, nBSV = 72\n",
      "Total nSV = 1043\n",
      "...*.*\n",
      "optimization finished, #iter = 4753\n",
      "obj = -274.680501, rho = -0.009778\n",
      "nSV = 1049, nBSV = 93\n",
      "Total nSV = 1049\n",
      "..*..*\n",
      "optimization finished, #iter = 4558\n",
      "obj = -264.563123, rho = 0.173504\n",
      "nSV = 1045, nBSV = 86\n",
      "Total nSV = 1045\n",
      "...*.*\n",
      "optimization finished, #iter = 4832\n",
      "obj = -266.973931, rho = -0.484026\n",
      "nSV = 1042, nBSV = 83\n",
      "Total nSV = 1042\n",
      "...*..*\n",
      "optimization finished, #iter = 5503\n",
      "obj = -309.469132, rho = 0.133421\n",
      "nSV = 1153, nBSV = 47\n",
      ".......*....*\n",
      "optimization finished, #iter = 11228\n",
      "obj = -668.933055, rho = 2.622938\n",
      "nSV = 2124, nBSV = 540\n",
      "Total nSV = 2124\n",
      ".......*...*\n",
      "optimization finished, #iter = 10394\n",
      "obj = -660.262641, rho = 2.712044\n",
      "nSV = 2079, nBSV = 522\n",
      "Total nSV = 2079\n",
      ".......*...*\n",
      "optimization finished, #iter = 10709\n",
      "obj = -660.833475, rho = 2.890056\n",
      "nSV = 2105, nBSV = 514\n",
      "Total nSV = 2105\n",
      ".......*...*\n",
      "optimization finished, #iter = 10747\n",
      "obj = -655.174527, rho = 2.831510\n",
      "nSV = 2088, nBSV = 488\n",
      "Total nSV = 2088\n",
      ".......*...*\n",
      "optimization finished, #iter = 10615\n",
      "obj = -648.231835, rho = 2.645499\n",
      "nSV = 2076, nBSV = 487\n",
      "Total nSV = 2076\n",
      "........*.....*.*\n",
      "optimization finished, #iter = 13292\n",
      "obj = -771.370311, rho = -2.842148\n",
      "nSV = 2337, nBSV = 884\n",
      "Total nSV = 9861\n",
      "SVM Accuracy Score ->  70.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83       750\n",
      "           1       0.74      0.44      0.55       750\n",
      "           2       0.53      0.63      0.58       750\n",
      "           3       0.73      0.95      0.83       750\n",
      "\n",
      "    accuracy                           0.70      3000\n",
      "   macro avg       0.72      0.70      0.70      3000\n",
      "weighted avg       0.72      0.70      0.70      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[591 110  33  16]\n",
      " [ 25 333 371  21]\n",
      " [ 49   4 476 221]\n",
      " [ 17   5  19 709]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "def add_glove_to_tfidf(tfidf_matrix, glove_embedding_matrix):\n",
    "    enhanced_tfidf_matrix = hstack([tfidf_matrix, glove_embedding_matrix])\n",
    "    return enhanced_tfidf_matrix\n",
    "\n",
    "X_train_tfidf_glove = add_glove_to_tfidf(X_train_clean_tfidf, X_train_vectors)\n",
    "X_test_tfidf_glove = add_glove_to_tfidf(X_test_clean_tfidf, X_test_vectors)\n",
    "_ = SVM(X_train_tfidf_glove, y_train, X_test_tfidf_glove, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T11:55:52.137707Z",
     "start_time": "2024-04-13T11:08:18.989924Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additional Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sentence Length \n",
    "- Count Booster Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/stella/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]....*....*.*\n",
      "optimization finished, #iter = 9456\n",
      "obj = -790.273763, rho = 1.006198\n",
      "nSV = 2245, nBSV = 454\n",
      "Total nSV = 2245\n",
      "......*..*\n",
      "optimization finished, #iter = 8024\n",
      "obj = -799.318501, rho = 0.965214\n",
      "nSV = 2231, nBSV = 354\n",
      "Total nSV = 2231\n",
      "......*..*\n",
      "optimization finished, #iter = 8013\n",
      "obj = -767.939409, rho = 0.994926\n",
      "nSV = 2200, nBSV = 391\n",
      "Total nSV = 2200\n",
      ".....*..*\n",
      "optimization finished, #iter = 7940\n",
      "obj = -787.390706, rho = 1.050144\n",
      "nSV = 2237, nBSV = 329\n",
      "Total nSV = 2237\n",
      "......*..*\n",
      "optimization finished, #iter = 8076\n",
      "obj = -785.092674, rho = 1.008163\n",
      "nSV = 2229, nBSV = 321\n",
      "Total nSV = 2229\n",
      "......*....*.*\n",
      "optimization finished, #iter = 10565\n",
      "obj = -903.863326, rho = -1.027343\n",
      "nSV = 2470, nBSV = 832\n",
      ".......*...*\n",
      "optimization finished, #iter = 10564\n",
      "obj = -1243.698809, rho = -0.130755\n",
      "nSV = 3880, nBSV = 1423\n",
      "Total nSV = 3880\n",
      ".......*...*\n",
      "optimization finished, #iter = 10925\n",
      "obj = -1254.426610, rho = -0.144228\n",
      "nSV = 3883, nBSV = 1459\n",
      "Total nSV = 3883\n",
      ".......*...*\n",
      "optimization finished, #iter = 10904\n",
      "obj = -1249.187141, rho = -0.157290\n",
      "nSV = 3870, nBSV = 1447\n",
      "Total nSV = 3870\n",
      ".......*...*\n",
      "optimization finished, #iter = 10507\n",
      "obj = -1274.323167, rho = -0.143823\n",
      "nSV = 3907, nBSV = 1578\n",
      "Total nSV = 3907\n",
      "........*..*\n",
      "optimization finished, #iter = 10875\n",
      "obj = -1234.282226, rho = -0.167025\n",
      "nSV = 3826, nBSV = 1451\n",
      "Total nSV = 3826\n",
      "........*....*\n",
      "optimization finished, #iter = 12584\n",
      "obj = -1444.830111, rho = 0.164798\n",
      "nSV = 4364, nBSV = 1227\n",
      "..........*...*\n",
      "optimization finished, #iter = 13527\n",
      "obj = -1891.081199, rho = 1.166419\n",
      "nSV = 4194, nBSV = 1423\n",
      "Total nSV = 4194\n",
      "..........*...*\n",
      "optimization finished, #iter = 13660\n",
      "obj = -1910.538889, rho = 1.122296\n",
      "nSV = 4264, nBSV = 1429\n",
      "Total nSV = 4264\n",
      "..........*....*\n",
      "optimization finished, #iter = 14023\n",
      "obj = -1910.666551, rho = 1.150867\n",
      "nSV = 4284, nBSV = 1426\n",
      "Total nSV = 4284\n",
      "........*.....*\n",
      "optimization finished, #iter = 13198\n",
      "obj = -1904.432835, rho = 1.195390\n",
      "nSV = 4241, nBSV = 1689\n",
      "Total nSV = 4241\n",
      ".........*....*\n",
      "optimization finished, #iter = 13265\n",
      "obj = -1888.708402, rho = 1.143205\n",
      "nSV = 4220, nBSV = 1374\n",
      "Total nSV = 4220\n",
      "............*....*\n",
      "optimization finished, #iter = 16087\n",
      "obj = -2235.515360, rho = -1.173673\n",
      "nSV = 4808, nBSV = 2010\n",
      ".......*..*\n",
      "optimization finished, #iter = 9150\n",
      "obj = -1015.315789, rho = -0.650301\n",
      "nSV = 2703, nBSV = 1088\n",
      "Total nSV = 2703\n",
      ".......*..*\n",
      "optimization finished, #iter = 9836\n",
      "obj = -1041.875389, rho = -0.654301\n",
      "nSV = 2758, nBSV = 1160\n",
      "Total nSV = 2758\n",
      ".......*..*\n",
      "optimization finished, #iter = 9784\n",
      "obj = -1048.208730, rho = -0.659154\n",
      "nSV = 2803, nBSV = 1135\n",
      "Total nSV = 2803\n",
      ".......*...*\n",
      "optimization finished, #iter = 10671\n",
      "obj = -1017.855306, rho = -0.667516\n",
      "nSV = 2724, nBSV = 985\n",
      "Total nSV = 2724\n",
      "......*....*\n",
      "optimization finished, #iter = 10992\n",
      "obj = -1047.185102, rho = -0.667238\n",
      "nSV = 2782, nBSV = 1008\n",
      "Total nSV = 2782\n",
      "........*....*\n",
      "optimization finished, #iter = 12345\n",
      "obj = -1202.256529, rho = 0.698667\n",
      "nSV = 3091, nBSV = 1171\n",
      ".....*.*\n",
      "optimization finished, #iter = 6591\n",
      "obj = -585.961314, rho = -0.090311\n",
      "nSV = 1667, nBSV = 280\n",
      "Total nSV = 1667\n",
      "....*..*\n",
      "optimization finished, #iter = 6422\n",
      "obj = -584.848505, rho = -0.098593\n",
      "nSV = 1664, nBSV = 283\n",
      "Total nSV = 1664\n",
      ".....*..*\n",
      "optimization finished, #iter = 7242\n",
      "obj = -569.608282, rho = -0.100126\n",
      "nSV = 1701, nBSV = 236\n",
      "Total nSV = 1701\n",
      "....*..*\n",
      "optimization finished, #iter = 6224\n",
      "obj = -581.425109, rho = -0.077681\n",
      "nSV = 1669, nBSV = 280\n",
      "Total nSV = 1669\n",
      ".....*..*\n",
      "optimization finished, #iter = 7317\n",
      "obj = -574.961985, rho = -0.081939\n",
      "nSV = 1693, nBSV = 291\n",
      "Total nSV = 1693\n",
      "....*.....*..*\n",
      "optimization finished, #iter = 11419\n",
      "obj = -662.544783, rho = 0.105265\n",
      "nSV = 1872, nBSV = 207\n",
      "..........*.*\n",
      "optimization finished, #iter = 11590\n",
      "obj = -1323.998857, rho = 0.515025\n",
      "nSV = 3597, nBSV = 1341\n",
      "Total nSV = 3597\n",
      "........*..*\n",
      "optimization finished, #iter = 10779\n",
      "obj = -1332.248291, rho = 0.520792\n",
      "nSV = 3627, nBSV = 1416\n",
      "Total nSV = 3627\n",
      "........*..*\n",
      "optimization finished, #iter = 10984\n",
      "obj = -1304.009922, rho = 0.515988\n",
      "nSV = 3564, nBSV = 1280\n",
      "Total nSV = 3564\n",
      "........*...*\n",
      "optimization finished, #iter = 11300\n",
      "obj = -1328.786462, rho = 0.505075\n",
      "nSV = 3582, nBSV = 1407\n",
      "Total nSV = 3582\n",
      ".......*....*\n",
      "optimization finished, #iter = 11369\n",
      "obj = -1319.841122, rho = 0.528518\n",
      "nSV = 3606, nBSV = 1341\n",
      "Total nSV = 3606\n",
      "..........*..*\n",
      "optimization finished, #iter = 12987\n",
      "obj = -1529.793742, rho = -0.536587\n",
      "nSV = 4072, nBSV = 1658\n",
      "Total nSV = 13420\n",
      "SVM Accuracy Score ->  74.16666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81       750\n",
      "           1       0.82      0.48      0.61       750\n",
      "           2       0.60      0.77      0.68       750\n",
      "           3       0.77      0.93      0.84       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.76      0.74      0.74      3000\n",
      "weighted avg       0.76      0.74      0.74      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[584  70  53  43]\n",
      " [ 45 363 305  37]\n",
      " [ 32  10 577 131]\n",
      " [ 26   2  21 701]]\n",
      "Time taken for Sentence Length on Processed dataset: 3525.296159029007 seconds\n",
      "[LibSVM]............*........*\n",
      "optimization finished, #iter = 20759\n",
      "obj = -788.324261, rho = 0.766792\n",
      "nSV = 2214, nBSV = 441\n",
      "Total nSV = 2214\n",
      "............*......*\n",
      "optimization finished, #iter = 18834\n",
      "obj = -787.829160, rho = 0.747917\n",
      "nSV = 2280, nBSV = 325\n",
      "Total nSV = 2280\n",
      "............*........*\n",
      "optimization finished, #iter = 20511\n",
      "obj = -790.589878, rho = 0.790451\n",
      "nSV = 2213, nBSV = 422\n",
      "Total nSV = 2213\n",
      "...............*..............*...*\n",
      "optimization finished, #iter = 31893\n",
      "obj = -785.494547, rho = 0.751154\n",
      "nSV = 2257, nBSV = 345\n",
      "Total nSV = 2257\n",
      "..............*.......*\n",
      "optimization finished, #iter = 21647\n",
      "obj = -796.246730, rho = 0.769839\n",
      "nSV = 2266, nBSV = 407\n",
      "Total nSV = 2266\n",
      ".................*..*\n",
      "optimization finished, #iter = 19940\n",
      "obj = -906.614961, rho = -0.793624\n",
      "nSV = 2497, nBSV = 680\n",
      "....................*....................*.........*\n",
      "optimization finished, #iter = 48823\n",
      "obj = -1204.685928, rho = -0.430179\n",
      "nSV = 3785, nBSV = 1394\n",
      "Total nSV = 3785\n",
      ".........................*..................*\n",
      "optimization finished, #iter = 43583\n",
      "obj = -1187.584071, rho = -0.441586\n",
      "nSV = 3786, nBSV = 1376\n",
      "Total nSV = 3786\n",
      ".......................*......................*..*\n",
      "optimization finished, #iter = 46421\n",
      "obj = -1217.328102, rho = -0.424391\n",
      "nSV = 3831, nBSV = 1429\n",
      "Total nSV = 3831\n",
      ".....................*.....................*..*\n",
      "optimization finished, #iter = 44410\n",
      "obj = -1198.265602, rho = -0.427958\n",
      "nSV = 3812, nBSV = 1379\n",
      "Total nSV = 3812\n",
      "......................*............................*........*\n",
      "optimization finished, #iter = 58236\n",
      "obj = -1198.788812, rho = -0.447649\n",
      "nSV = 3782, nBSV = 1399\n",
      "Total nSV = 3782\n",
      "......................*..............*.*\n",
      "optimization finished, #iter = 36804\n",
      "obj = -1383.825236, rho = 0.457850\n",
      "nSV = 4226, nBSV = 1521\n",
      "........................*.........................*.............*.*\n",
      "optimization finished, #iter = 62249\n",
      "obj = -1898.915658, rho = 0.843499\n",
      "nSV = 4226, nBSV = 1420\n",
      "Total nSV = 4226\n",
      "...................*.............................*....................*.*\n",
      "optimization finished, #iter = 68082\n",
      "obj = -1894.040489, rho = 0.831208\n",
      "nSV = 4203, nBSV = 1509\n",
      "Total nSV = 4203\n",
      ".......................*...................*.*\n",
      "optimization finished, #iter = 43013\n",
      "obj = -1900.420588, rho = 0.882488\n",
      "nSV = 4258, nBSV = 1392\n",
      "Total nSV = 4258\n",
      "...............*...............................*....*\n",
      "optimization finished, #iter = 50329\n",
      "obj = -1894.476196, rho = 0.857469\n",
      "nSV = 4215, nBSV = 1448\n",
      "Total nSV = 4215\n",
      "...................*...........................*...*\n",
      "optimization finished, #iter = 49315\n",
      "obj = -1907.400321, rho = 0.836268\n",
      "nSV = 4285, nBSV = 1559\n",
      "Total nSV = 4285\n",
      "........................*.........................*..*\n",
      "optimization finished, #iter = 50439\n",
      "obj = -2228.454572, rho = -0.879639\n",
      "nSV = 4817, nBSV = 2018\n",
      "............*.............*....*\n",
      "optimization finished, #iter = 29221\n",
      "obj = -937.530491, rho = -0.878421\n",
      "nSV = 2580, nBSV = 973\n",
      "Total nSV = 2580\n",
      ".............*................*....*\n",
      "optimization finished, #iter = 32826\n",
      "obj = -939.295413, rho = -0.889613\n",
      "nSV = 2555, nBSV = 937\n",
      "Total nSV = 2555\n",
      "................*...*\n",
      "optimization finished, #iter = 19986\n",
      "obj = -935.325802, rho = -0.891419\n",
      "nSV = 2596, nBSV = 915\n",
      "Total nSV = 2596\n",
      "............*..............*..*\n",
      "optimization finished, #iter = 27633\n",
      "obj = -941.065666, rho = -0.895984\n",
      "nSV = 2582, nBSV = 977\n",
      "Total nSV = 2582\n",
      ".................*......*\n",
      "optimization finished, #iter = 23508\n",
      "obj = -919.366157, rho = -0.876712\n",
      "nSV = 2528, nBSV = 1019\n",
      "Total nSV = 2528\n",
      "...............*.........*\n",
      "optimization finished, #iter = 24817\n",
      "obj = -1083.645614, rho = 0.925200\n",
      "nSV = 2889, nBSV = 951\n",
      ".........*.......*.*\n",
      "optimization finished, #iter = 16468\n",
      "obj = -567.646973, rho = -0.186317\n",
      "nSV = 1660, nBSV = 205\n",
      "Total nSV = 1660\n",
      ".........*...*\n",
      "optimization finished, #iter = 12942\n",
      "obj = -565.057118, rho = -0.189276\n",
      "nSV = 1659, nBSV = 219\n",
      "Total nSV = 1659\n",
      "........*.........*.*\n",
      "optimization finished, #iter = 17765\n",
      "obj = -573.199179, rho = -0.174893\n",
      "nSV = 1663, nBSV = 199\n",
      "Total nSV = 1663\n",
      ".........*......*\n",
      "optimization finished, #iter = 15551\n",
      "obj = -573.031664, rho = -0.212227\n",
      "nSV = 1640, nBSV = 242\n",
      "Total nSV = 1640\n",
      "...........*....*\n",
      "optimization finished, #iter = 15399\n",
      "obj = -565.869488, rho = -0.150709\n",
      "nSV = 1669, nBSV = 177\n",
      "Total nSV = 1669\n",
      "...............*...*\n",
      "optimization finished, #iter = 18734\n",
      "obj = -651.021972, rho = 0.195798\n",
      "nSV = 1850, nBSV = 228\n",
      "..............*.............*.*\n",
      "optimization finished, #iter = 28085\n",
      "obj = -1292.434037, rho = 0.561713\n",
      "nSV = 3543, nBSV = 1161\n",
      "Total nSV = 3543\n",
      ".............*.........*\n",
      "optimization finished, #iter = 22814\n",
      "obj = -1281.299175, rho = 0.574500\n",
      "nSV = 3550, nBSV = 862\n",
      "Total nSV = 3550\n",
      "................*........*\n",
      "optimization finished, #iter = 24425\n",
      "obj = -1313.546053, rho = 0.558087\n",
      "nSV = 3586, nBSV = 1130\n",
      "Total nSV = 3586\n",
      "...............*..........*\n",
      "optimization finished, #iter = 25731\n",
      "obj = -1291.832198, rho = 0.576531\n",
      "nSV = 3565, nBSV = 1216\n",
      "Total nSV = 3565\n",
      "..............*.............*\n",
      "optimization finished, #iter = 27899\n",
      "obj = -1295.047497, rho = 0.551494\n",
      "nSV = 3554, nBSV = 1098\n",
      "Total nSV = 3554\n",
      "..............................*...................*.*\n",
      "optimization finished, #iter = 49843\n",
      "obj = -1499.473282, rho = -0.581811\n",
      "nSV = 3987, nBSV = 1675\n",
      "Total nSV = 13201\n",
      "SVM Accuracy Score ->  75.16666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       750\n",
      "           1       0.81      0.52      0.63       750\n",
      "           2       0.63      0.77      0.69       750\n",
      "           3       0.76      0.94      0.84       750\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.77      0.75      0.75      3000\n",
      "weighted avg       0.77      0.75      0.75      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[589  78  39  44]\n",
      " [ 40 387 284  39]\n",
      " [ 31  10 575 134]\n",
      " [ 26   1  19 704]]\n",
      "Time taken for Count Booster Words on Processed dataset: 3677.1671187877655 seconds\n"
     ]
    }
   ],
   "source": [
    "# Count sentence length\n",
    "# Count of booster words (with preprocessing)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from scipy.sparse import hstack\n",
    "import time\n",
    "\n",
    "# Uncomment if you have not downloaded the 'punkt' and 'averaged_perceptron_tagger' packages\n",
    "nltk.download('punkt') \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def add_custom_feature_to_tfidf(data, tfidf_matrix, feature_extraction_func):\n",
    "    custom_feature = data.apply(feature_extraction_func)\n",
    "    custom_feature_sparse = np.array(custom_feature).reshape(-1, 1)\n",
    "    enhanced_tfidf_matrix = hstack([tfidf_matrix, custom_feature_sparse])\n",
    "    return enhanced_tfidf_matrix\n",
    "\n",
    "# Feature extraction functions\n",
    "def count_sentence_length(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "def count_quotations(text):\n",
    "    return text.count('\"')\n",
    "\n",
    "def count_numbers(text):\n",
    "    return len(re.findall(r'\\d+', text))\n",
    "\n",
    "def count_proper_nouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    proper_nouns = [word for word, pos in tagged if pos == 'NNP']\n",
    "    return len(proper_nouns)\n",
    "\n",
    "def count_conjunctions(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    conjunctions = [word for word, pos in tagged if pos == 'CC']\n",
    "    return len(conjunctions)\n",
    "\n",
    "def count_superlatives(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    superlatives = [word for word, pos in tagged if pos == 'JJS']\n",
    "    return len(superlatives)\n",
    "\n",
    "def count_1st_pronouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    first_pronouns = [word for word, pos in tagged if pos == 'PRP' and word.lower() in ['i', 'me', 'my', 'mine']]\n",
    "    return len(first_pronouns)\n",
    "\n",
    "def count_3rd_pronouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    third_pronouns = [word for word, pos in tagged if pos == 'PRP' and word.lower() in \n",
    "                      ['he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'they', 'them', 'their', 'theirs']]\n",
    "    return len(third_pronouns)\n",
    "\n",
    "def count_booster_words(text):\n",
    "    booster_words = \"\"\"absolutely amazingly awfully completely considerably definitely entirely exceedingly\n",
    "                    extremely highly incredibly indeed quite really remarkably so terribly totally truly utterly very\"\"\"\n",
    "    booster_words = booster_words.split(\" \")\n",
    "    return len([word for word in text.split(\" \") if word in booster_words])\n",
    "\n",
    "# Evaluate the performance of the model with the custom features\n",
    "# For the purpose of comparison, we can just use the logistic regression model across all the custom features\n",
    "features_methods_dictionary =  {\n",
    "    \"Sentence Length\": count_sentence_length, #ok\n",
    "    # \"Count Quotations\": count_quotations,\n",
    "    # \"Count Numbers\": count_numbers,\n",
    "    # \"Count Proper Nouns\": count_proper_nouns,\n",
    "    # \"Count Conjunctions\": count_conjunctions,\n",
    "    # \"Count Superlatives\": count_superlatives,\n",
    "    # \"Count 1st Pronouns\": count_1st_pronouns,\n",
    "    # \"Count 3rd Pronouns\": count_3rd_pronouns,\n",
    "    \"Count Booster Words\": count_booster_words # ok\n",
    "}\n",
    "\n",
    "training_datasets = {\n",
    "    # \"Not Processed\": [X_train, X_train_tfidf, X_test, X_test_tfidf],\n",
    "    \"Processed\": [X_train_clean, X_train_clean_tfidf, X_test_clean, X_test_clean_tfidf]\n",
    "}\n",
    "for dataset_name , datasets in training_datasets.items():\n",
    "    X_train = datasets[0]\n",
    "    X_train_tfidf = datasets[1]\n",
    "    X_test = datasets[2]\n",
    "    X_test_tfidf = datasets[3]\n",
    "    if not (isinstance(X_train, pd.Series) or isinstance(X_train, pd.DataFrame)):\n",
    "        X_train = pd.Series(X_train)\n",
    "    if not (isinstance(X_test, pd.Series) or isinstance(X_test, pd.DataFrame)):\n",
    "        X_test = pd.Series(X_test)\n",
    "    for feature_name, feature_matrix in features_methods_dictionary.items():\n",
    "        time_start = time.time()\n",
    "        if dataset_name == \"Not Processed\":\n",
    "            X_train_enhanced = add_custom_feature_to_tfidf(X_train, X_train_tfidf, feature_matrix)\n",
    "            X_test_enhanced = add_custom_feature_to_tfidf(X_test, X_test_tfidf, feature_matrix)\n",
    "        else:\n",
    "            X_train_enhanced = add_custom_feature_to_tfidf(X_train, X_train_tfidf, feature_matrix)\n",
    "            X_test_enhanced = add_custom_feature_to_tfidf(X_test, X_test_tfidf, feature_matrix)\n",
    "        _ = SVM(X_train_enhanced, y_train, X_test_enhanced, y_test)\n",
    "        time_end = time.time()\n",
    "        print(f\"Time taken for {feature_name} on {dataset_name} dataset: {time_end - time_start} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T23:38:38.947964Z",
     "start_time": "2024-04-09T21:38:36.338162Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tfidf + word embeddings + sentence length + booster words count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  71.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83       750\n",
      "           1       0.75      0.47      0.58       750\n",
      "           2       0.55      0.64      0.59       750\n",
      "           3       0.73      0.94      0.82       750\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.72      0.71      0.71      3000\n",
      "weighted avg       0.72      0.71      0.71      3000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[596 107  30  17]\n",
      " [ 28 353 348  21]\n",
      " [ 40   5 479 226]\n",
      " [ 21   5  16 708]]\n",
      "Time taken on Processed dataset: 2949.589693069458 seconds\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def add_custom_feature_to_vectors(data, vector_matrix, methods_dictionary):\n",
    "    temp_matrix = copy.deepcopy(vector_matrix)\n",
    "    for _, feature_func in methods_dictionary.items():\n",
    "        custom_feature = data.apply(feature_func)\n",
    "        custom_feature_sparse = np.array(custom_feature).reshape(-1, 1)\n",
    "        temp_matrix = hstack([temp_matrix, custom_feature_sparse])\n",
    "    return temp_matrix\n",
    "\n",
    "optimal_features_methods_dictionary =  {\n",
    "    \"Sentence Length\": count_sentence_length, \n",
    "    \"Count Booster Words\": count_booster_words \n",
    "}\n",
    "\n",
    "training_datasets = {\n",
    "    # \"Not Processed\": [X_train, X_train_tfidf_glove, X_test, X_test_tfidf_glove],\n",
    "    \"Processed\": [X_train_clean, X_train_tfidf_glove, X_test_clean, X_test_tfidf_glove]\n",
    "}\n",
    "for dataset_name , datasets in training_datasets.items():\n",
    "    X_train = datasets[0]\n",
    "    X_train_tfidf = datasets[1]\n",
    "    X_test = datasets[2]\n",
    "    X_test_tfidf = datasets[3]\n",
    "    if not (isinstance(X_train, pd.Series) or isinstance(X_train, pd.DataFrame)):\n",
    "        X_train = pd.Series(X_train)\n",
    "    if not (isinstance(X_test, pd.Series) or isinstance(X_test, pd.DataFrame)):\n",
    "        X_test = pd.Series(X_test)\n",
    "    if not (isinstance(X_train_clean, pd.Series) or isinstance(X_train_clean, pd.DataFrame)):\n",
    "        X_train_clean = pd.Series(X_train_clean)\n",
    "    if not (isinstance(X_test_clean, pd.Series) or isinstance(X_test_clean, pd.DataFrame)):\n",
    "        X_test_clean = pd.Series(X_test_clean)\n",
    "\n",
    "    time_start = time.time()\n",
    "    if dataset_name == \"Not Processed\":\n",
    "        X_train_enhanced = add_custom_feature_to_vectors(X_train, X_train_tfidf_glove, optimal_features_methods_dictionary)\n",
    "        X_test_enhanced = add_custom_feature_to_vectors(X_test, X_test_tfidf_glove, optimal_features_methods_dictionary)\n",
    "    else:\n",
    "        X_train_enhanced = add_custom_feature_to_vectors(X_train_clean, X_train_tfidf_glove, optimal_features_methods_dictionary)\n",
    "        X_test_enhanced = add_custom_feature_to_vectors(X_test_clean, X_test_tfidf_glove, optimal_features_methods_dictionary)\n",
    "    _ = SVM(X_train_enhanced, y_train, X_test_enhanced, y_test)\n",
    "    time_end = time.time()\n",
    "    print(f\"Time taken on {dataset_name} dataset: {time_end - time_start} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T14:46:24.095922Z",
     "start_time": "2024-04-13T13:57:14.502068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
