{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyI5SA6HIoRH"
   },
   "source": [
    "# CS4248 Project\n",
    "(DON'T CLICK RUN ALL! Lemmatization takes tooo long and pls don't run it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS033yHSHyAx",
    "outputId": "e923c9e4-6bda-4a5a-970a-3bdd5ee92c59",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:08.052298Z",
     "start_time": "2024-03-03T12:43:07.925947Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# \n",
    "# %cd \"/content/drive/My Drive/CS4248 Project\"\n",
    "# !cd \"/content/drive/My Drive/CS4248 Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2nqSeqYQJ4vW",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:08.736833Z",
     "start_time": "2024-03-03T12:43:07.927851Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9PepPt_CL94x",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:09.599261Z",
     "start_time": "2024-03-03T12:43:08.737465Z"
    }
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(999999)\n",
    "train = pd.read_csv('raw_data/fulltrain.csv', header = None, names=['class','text'])\n",
    "X_train = train['text']\n",
    "y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sCT1xI_yXFJO",
    "outputId": "172bcde2-37a1-40c2-e329-f0152f49ab50",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:09.607016Z",
     "start_time": "2024-03-03T12:43:09.600873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   class                                               text\n0      1  A little less than a decade ago, hockey fans w...\n1      1  The writers of the HBO series The Sopranos too...\n2      1  Despite claims from the TV news outlet to offe...\n3      1  After receiving 'subpar' service and experienc...\n4      1  After watching his beloved Seattle Mariners pr...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A little less than a decade ago, hockey fans w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>The writers of the HBO series The Sopranos too...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Despite claims from the TV news outlet to offe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>After receiving 'subpar' service and experienc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>After watching his beloved Seattle Mariners pr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-FcMBozxWAvz",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:09.671723Z",
     "start_time": "2024-03-03T12:43:09.607333Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"raw_data/balancedtest.csv\", header = None, names=['class','text'])\n",
    "X_test = test['text']\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s5befmSMXN8N",
    "outputId": "c1aef16d-ccb9-4036-f8af-1a6c9d16c035",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:09.674994Z",
     "start_time": "2024-03-03T12:43:09.662004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   class                                               text\n0      1  When so many actors seem content to churn out ...\n1      1   In what football insiders are calling an unex...\n2      1  In a freak accident following Game 3 of the N....\n3      1  North Koreas official news agency announced to...\n4      1  The former Alaska Governor Sarah Palin would b...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When so many actors seem content to churn out ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>In what football insiders are calling an unex...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>In a freak accident following Game 3 of the N....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>North Koreas official news agency announced to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>The former Alaska Governor Sarah Palin would b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WOxbEhspgUT"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NKfM8O-nbbpJ",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:19.168882Z",
     "start_time": "2024-03-03T12:43:09.714397Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(X_train, X_test):\n",
    "\n",
    "  tfidf_baseline = TfidfVectorizer(ngram_range=(1,1), max_features = 10000)\n",
    "\n",
    "  X_train_tfidf = tfidf_baseline.fit_transform(X_train)\n",
    "\n",
    "  X_test_tfidf = tfidf_baseline.transform(X_test)\n",
    "\n",
    "  return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDCcR3tOpJ-e",
    "outputId": "c1bc4bd9-bf63-4b1a-902b-147b1c243360",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:25.273195Z",
     "start_time": "2024-03-03T12:43:19.166466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.79      0.82       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.56      0.83      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.71      3000\n",
      "weighted avg       0.76      0.73      0.71      3000\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - baseline\n",
    "\n",
    "def LR(X_train_tfidf, y_train, X_test_tfidf):\n",
    "\n",
    "  LR_classifier = LogisticRegression(random_state = 42, max_iter=1000).fit(X_train_tfidf, y_train)\n",
    "\n",
    "  y_pred_lr = LR_classifier.predict(X_test_tfidf)\n",
    "\n",
    "  print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "  return y_pred_lr\n",
    "\n",
    "y_pred_lr = LR(X_train_tfidf, y_train, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQyWjGLUxREy",
    "outputId": "e4827d40-70fe-44b0-ecd2-9c271deaf5dd",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:25.327008Z",
     "start_time": "2024-03-03T12:43:25.274214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.61      0.61       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.68      0.67      0.66      3000\n",
      "weighted avg       0.68      0.67      0.66      3000\n"
     ]
    }
   ],
   "source": [
    "# NB - baseline\n",
    "\n",
    "def NB(X_train_tfidf, y_train, X_test_tfidf):\n",
    "\n",
    "  nb_classifier = ComplementNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "  y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "  print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "  return y_pred_nb\n",
    "\n",
    "y_pred_nb = NB(X_train_tfidf, y_train, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITNfwpWkt1OI"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lemmatization with POS Tagging\n",
    "(DON'T RUN AGAIN! It takes tooooo long)"
   ],
   "metadata": {
    "id": "z6Yrnd2f_y5W"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E3t6cQp1r-N",
    "outputId": "45aad408-e2fc-4eea-d48b-c4cd161199bd",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:25.546206Z",
     "start_time": "2024-03-03T12:43:25.310784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/stella/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to lemmatize each word with its POS tag\n",
    "\n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_with_pos(tokens):\n",
    "  # tokenize the sentence and find the POS tag for each token\n",
    "  pos_tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "  # print(pos_tagged)\n",
    "\n",
    "  wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "  # print(wordnet_tagged)\n",
    "\n",
    "  lemmatized_sentence = []\n",
    "  for word, tag in wordnet_tagged:\n",
    "      if tag is None:\n",
    "          # if there is no available tag, append the token as is\n",
    "          lemmatized_sentence.append(word)\n",
    "      else:\n",
    "          # else use the tag to lemmatize the token\n",
    "          lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "  # lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "\n",
    "  # print(lemmatized_sentence)\n",
    "  return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-3cE9Qzt3zY",
    "outputId": "dd07285c-1ccd-41b5-c9d3-78d8174a7cb1",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:54:52.363669Z",
     "start_time": "2024-03-03T12:43:25.540072Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in /opt/homebrew/lib/python3.11/site-packages (0.8.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [10:48<00:00, 75.28it/s] \n",
      "100%|██████████| 3000/3000 [00:36<00:00, 81.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "['A little less than a decade ago hockey fan be bless with a slate of game every night but on Thursday source confirm that for the ninth consecutive year NHL player have be lock out with very slim hope of an agreement in sight It seem like just yesterday Martin St. Louis and his Lightning teammate be raise the Stanley Cup high school hockey coach and onetime ESPN analyst Barry Melrose say Obviously Im still hop the two side can come together and reach an agreement but Im start to think nobody really miss hockey anymore Nope Nobody but old Barry Id still love to catch an Atlanta Thrashers game Observers have note that when arena door do reopen the NHL will face the perhaps great challenge of convince fan to return to hockey instead of watch more popular sport like football basketball baseball and SlamBall',\n \"The writer of the HBO series The Sopranos take another dare storytelling step by kill off million fan during the seventh season 's premiere episode Sunday night 'This be definitely a bold choice one that producer of the show would have never think of make five year ago say New York Times television critic Virginia Heffernan who note that the move be hint at in a season-five episode in which Tony dreamt he be rid a horse through his house 'But now that I look back this be strongly foreshadow throughout all of last season Industry insider predict that the show 's producer would try to bring at least some fan back for the series finale which may come as early as May\"]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start preprocessing\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def preprocessing(data):\n",
    "  data_clean = []\n",
    "  for sentence in tqdm(data):\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Remove punctuation and number\n",
    "    tokens = [w for w in tokens if (not w in punc) and (not w.isdigit())]\n",
    "\n",
    "    # Spell check\n",
    "    # Taking too long time for each sentence, not practical to be used\n",
    "    # tokens = [spell.correction(w) for w in tokens]\n",
    "    # tokens = [w for w in tokens if w is not None and len(w) > 0]\n",
    "\n",
    "    # Lemmatization based on tagging\n",
    "    tokens = lemmatize_with_pos(tokens)\n",
    "\n",
    "    data_clean.append((' ').join(tokens))\n",
    "  return data_clean\n",
    "\n",
    "\n",
    "X_train_clean = preprocessing(X_train)\n",
    "X_test_clean = preprocessing(X_test)\n",
    "\n",
    "X_train_clean[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nH-JuFWdzqHa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e641367-5188-4e56-8a83-b04dbde46ec0",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:55:07.439512Z",
     "start_time": "2024-03-03T12:54:52.361889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.84      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.75      0.74      3000\n",
      "weighted avg       0.77      0.74      0.74      3000\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_tfidf, X_test_clean_tfidf = tfidf(X_train_clean, X_test_clean)\n",
    "\n",
    "_ = LR(X_train_clean_tfidf, y_train, X_test_clean_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = NB(X_train_clean_tfidf, y_train, X_test_clean_tfidf)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu2641T-HNd3",
    "outputId": "ba6f10d5-8b1f-4365-be7e-11ca479109bc",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:55:07.502437Z",
     "start_time": "2024-03-03T12:55:07.437285Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.65      0.51      0.57       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTufYR0Gt4Wi"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "h4_ImWMZt6Ru",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:56:15.269645Z",
     "start_time": "2024-03-03T12:55:07.474084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text Subjectivity (w/o preprocessing)\n",
    "from textblob import TextBlob\n",
    "\n",
    "def subjectivity(data, tf_idf):\n",
    "    # new_data = data.copy()\n",
    "    new_data = data\n",
    "    new_data['psycho-linguistic'] = new_data[\"text\"].apply(lambda x: TextBlob(x).sentiment)\n",
    "    new_data['subjectivity'] = new_data['psycho-linguistic'].apply(lambda x: x[1])\n",
    "    tfidf_df = pd.DataFrame(tf_idf.toarray())\n",
    "    subject_df = pd.merge(tfidf_df, new_data['subjectivity'],left_index=True, right_index=True)\n",
    "    subject_df.columns = subject_df.columns.astype(str)\n",
    "    return subject_df\n",
    "\n",
    "train_subject_df = subjectivity(train, X_train_tfidf)\n",
    "test_subject_df = subjectivity(test, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = LR(train_subject_df, y_train, test_subject_df)"
   ],
   "metadata": {
    "id": "eqxPbQkservd",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:57:00.593547Z",
     "start_time": "2024-03-03T12:56:15.270976Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.57      0.82      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.72      3000\n",
      "weighted avg       0.76      0.73      0.72      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = NB(train_subject_df, y_train, test_subject_df)"
   ],
   "metadata": {
    "id": "qLCfOSineuZA",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:57:01.581904Z",
     "start_time": "2024-03-03T12:57:00.616100Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.68      0.67      0.66      3000\n",
      "weighted avg       0.68      0.67      0.66      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Text Subjectivity (with preprocessing)\n",
    "train_clean_subject_df = subjectivity(train, X_train_clean_tfidf)\n",
    "test_clean_subject_df = subjectivity(test, X_test_clean_tfidf)"
   ],
   "metadata": {
    "id": "Z8wmIXUvewcx",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:58:09.782527Z",
     "start_time": "2024-03-03T12:57:01.638560Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_ = LR(train_clean_subject_df, y_train, test_clean_subject_df)"
   ],
   "metadata": {
    "id": "Oz5HO9tEey_y",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:58:48.296884Z",
     "start_time": "2024-03-03T12:58:09.806196Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       750\n",
      "           2       0.83      0.40      0.54       750\n",
      "           3       0.58      0.83      0.69       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = NB(train_clean_subject_df, y_train, test_clean_subject_df)"
   ],
   "metadata": {
    "id": "3Uyp0kzUe1V_",
    "ExecuteTime": {
     "end_time": "2024-03-03T12:58:50.812512Z",
     "start_time": "2024-03-03T12:58:48.284990Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.64      0.51      0.57       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.87      0.65      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Hedging Word Count (w/o preprocessing)\n",
    "#source: http://jal.iaut.ac.ir/article_524171_19ce974d4c9441a312df2d6eaac20a15.pdf\n",
    "#https://hal.inria.fr/hal-03342756/file/Besancon__Definitely_Maybe__preprint%20%281%29.pdf\n",
    "import re\n",
    "modal = \"Can Could May Might Should Will Would\"\n",
    "re_modal = \"(?:^|\\W)(\" + \"|\".join(modal.lower().split(\" \")) + \")(?:$|\\W)\"\n",
    "\n",
    "lexical = \"Appear Argue Assert Assume Attempt Believe Claim Conclude Consider Doubt Estimate Evaluate Expect Feel Hypothesize Imply Indicate Interpret Maintain Note Offer Observe Perceive Presume Propose Prove Report Seem Seen Speculate Suggest Suppose Suspect Tend Think\"\n",
    "lexical_s = [i + \"s\" for i in lexical.lower().split(\" \")]\n",
    "re_lexical = \"(?:^|\\W)(\" + \"|\".join(lexical.lower().split(\" \") + lexical_s) + \"|attempt to|can be seen\" + \")(?:$|\\W)\"\n",
    "\n",
    "adverbs = \"About Allegedly Almost Apparently Approximately Around Arguably Barely Commonly Conceivably Considerably Doubtless Fairly Frequently Generally Given that Greatly Highly Hypothetically Largely Likely Mainly Markedly Maybe Modestly Mostly Nearly Normally Occasionally Often Partially Partly Perhaps Possibly Potentially Practically Presumably Primarily Probably Provided Quite Rarely Reasonably Relatively Reportedly Roughly Seemingly Seldom Significantly Slightly Sometimes Somewhat Strongly Substantially Supposedly Tentatively Theoretically Typically Unlikely Usually Vastly Virtually Widely\"\n",
    "re_adverbs = \"(?:^|\\W)(\" + \"|\".join(adverbs.lower().split(\" \")) + \"|provided that\" + \")(?:$|\\W)\"\n",
    "\n",
    "adjectives = \"Apparent Approximate Common Conceivable Considerable Consistent with Frequent General Hypothetical Improbable Indicative Large Likely Little Main Major Modest Noticeable Plausible Possible Potential Primary Probable Rare Relative Remarkable Rough Significant Slight Small Substantial Theoretical Typical Uncommon Unlikely Usual Well-Known\"\n",
    "re_adjectives = \"(?:^|\\W)(\" + \"|\".join(adjectives.lower().split(\" \")) + \")(?:$|\\W)\"\n",
    "\n",
    "nouns = \"Alternative Approximation Assertion Assessment Assumption Belief Chance Claim Conclusion Doubt Estimate Estimation Evaluation Expectation Hope Idea Implication Indication Interpretation Likelihood Opinion Possibility Premise Probability Proposal Suggestion Tendency View\"\n",
    "re_nouns = \"(?:^|\\W)(\" + \"|\".join(nouns.lower().split(\" \")) + \")(?:$|\\W)\""
   ],
   "metadata": {
    "id": "I016Kj7me2_3",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:35:09.921099Z",
     "start_time": "2024-03-03T13:35:09.912359Z"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def hedges(x):\n",
    "    if (len(re.findall(re_modal,x.lower())) +\n",
    "            len(re.findall(re_lexical,x.lower())) +\n",
    "            len(re.findall(re_adverbs,x.lower())) +\n",
    "            len(re.findall(re_adjectives,x.lower())) +\n",
    "            len(re.findall(re_nouns,x.lower()))) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def hedging_word_count(data, tf_idf):\n",
    "    new_data = data.copy()\n",
    "    new_data[\"hedges\"] = new_data.loc[:, \"text\"].apply(hedges)\n",
    "    tfidf_df = pd.DataFrame(tf_idf.toarray())\n",
    "    hedged_df = pd.merge(tfidf_df, new_data['hedges'],left_index=True, right_index=True)\n",
    "    hedged_df.columns = hedged_df.columns.astype(str)\n",
    "    return hedged_df\n",
    "\n",
    "train_hedge_df = hedging_word_count(train, X_train_tfidf)\n",
    "test_hedge_df = hedging_word_count(test, X_test_tfidf)"
   ],
   "metadata": {
    "id": "rW1VPfN4e6FY",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:36:00.245036Z",
     "start_time": "2024-03-03T13:35:12.409392Z"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_ = LR(train_hedge_df, y_train, test_hedge_df)"
   ],
   "metadata": {
    "id": "-0fGAXTwe8No",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:36:57.244185Z",
     "start_time": "2024-03-03T13:36:00.260792Z"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.82      0.83       750\n",
      "           2       0.80      0.36      0.50       750\n",
      "           3       0.57      0.83      0.68       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.75      0.73      0.72      3000\n",
      "weighted avg       0.75      0.73      0.72      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = NB(train_hedge_df, y_train, test_hedge_df)"
   ],
   "metadata": {
    "id": "V_EZcIXQfD-t",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:36:59.075948Z",
     "start_time": "2024-03-03T13:36:57.240045Z"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.66      3000\n",
      "weighted avg       0.69      0.67      0.66      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Hedging Word Count (with preprocessing)\n",
    "train_clean_hedge_df = hedging_word_count(train, X_train_clean_tfidf)\n",
    "test_clean_hedge_df = hedging_word_count(test, X_test_clean_tfidf)"
   ],
   "metadata": {
    "id": "rYz1yM-ffFyo",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:37:47.526460Z",
     "start_time": "2024-03-03T13:36:59.082454Z"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_ = LR(train_clean_hedge_df, y_train, test_clean_hedge_df)"
   ],
   "metadata": {
    "id": "mYjo7t8AfIMg",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:38:35.662288Z",
     "start_time": "2024-03-03T13:37:47.549055Z"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.83      0.84       750\n",
      "           2       0.82      0.41      0.54       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.80      0.91      0.85       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "_ = NB(train_clean_hedge_df, y_train, test_clean_hedge_df)"
   ],
   "metadata": {
    "id": "GzySa4unfL_F",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:38:37.122653Z",
     "start_time": "2024-03-03T13:38:35.677026Z"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.64      0.51      0.57       750\n",
      "           3       0.63      0.91      0.75       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "HgSb6hNwfNmO",
    "ExecuteTime": {
     "end_time": "2024-03-03T13:38:37.122924Z",
     "start_time": "2024-03-03T13:38:37.121971Z"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
