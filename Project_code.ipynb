{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyI5SA6HIoRH"
   },
   "source": [
    "# CS4248 Project\n",
    "(DON'T CLICK RUN ALL! Lemmatization takes tooo long and pls don't run it again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T12:43:08.052298Z",
     "start_time": "2024-03-03T12:43:07.925947Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS033yHSHyAx",
    "outputId": "e923c9e4-6bda-4a5a-970a-3bdd5ee92c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.8.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
      "Collecting numpy==1.25.1\n",
      "  Downloading numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "     ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/15.0 MB 5.0 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.6/15.0 MB 5.8 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 1.0/15.0 MB 7.6 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 1.0/15.0 MB 5.8 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.5/15.0 MB 6.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.8/15.0 MB 6.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 2.2/15.0 MB 6.7 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.6/15.0 MB 7.1 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 3.0/15.0 MB 7.1 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.4/15.0 MB 7.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.9/15.0 MB 7.5 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 4.3/15.0 MB 7.9 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.7/15.0 MB 7.7 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 5.2/15.0 MB 7.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 5.6/15.0 MB 8.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.9/15.0 MB 7.9 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 6.4/15.0 MB 8.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 6.8/15.0 MB 8.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 7.2/15.0 MB 8.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 7.6/15.0 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.3/15.0 MB 8.4 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 8.8/15.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 9.1/15.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.6/15.0 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 10.2/15.0 MB 8.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 10.4/15.0 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 10.8/15.0 MB 9.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 11.0/15.0 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 11.6/15.0 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.9/15.0 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 12.1/15.0 MB 8.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.5/15.0 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.9/15.0 MB 9.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.4/15.0 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.7/15.0 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 14.1/15.0 MB 8.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 14.4/15.0 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.8/15.0 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.0/15.0 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.0/15.0 MB 8.5 MB/s eta 0:00:00\n",
      "Collecting pandas==2.1.1\n",
      "  Downloading pandas-2.1.1-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/10.7 MB 33.5 MB/s eta 0:00:01\n",
      "     -- ------------------------------------- 0.8/10.7 MB 8.3 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.3/10.7 MB 10.6 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.7/10.7 MB 9.1 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 2.2/10.7 MB 10.1 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 2.4/10.7 MB 8.8 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.7/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 2.9/10.7 MB 7.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.3/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.3/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.5/10.7 MB 6.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.0/10.7 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 4.3/10.7 MB 7.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 4.7/10.7 MB 7.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 5.2/10.7 MB 7.4 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 5.6/10.7 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 5.9/10.7 MB 7.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 6.4/10.7 MB 7.7 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.7/10.7 MB 7.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 7.1/10.7 MB 7.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.5/10.7 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 8.1/10.7 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.5/10.7 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.8/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.4/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 9.9/10.7 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.2/10.7 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.7/10.7 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.7/10.7 MB 7.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyspellchecker==0.8.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==1.4.1.post1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 5)) (1.4.1.post1)\n",
      "Collecting tqdm==4.65.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: textblob in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from -r requirements.txt (line 7)) (0.18.0.post0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm==4.65.0->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas==2.1.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Installing collected packages: tqdm, numpy, pandas\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.0\n",
      "    Uninstalling pandas-2.0.0:\n",
      "      Successfully uninstalled pandas-2.0.0\n",
      "Successfully installed numpy-1.25.1 pandas-2.1.1 tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# \n",
    "# %cd \"/content/drive/My Drive/CS4248 Project\"\n",
    "# !cd \"/content/drive/My Drive/CS4248 Project\"\n",
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:33.330247Z",
     "start_time": "2024-03-05T16:49:33.275009Z"
    },
    "id": "2nqSeqYQJ4vW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:34.929285Z",
     "start_time": "2024-03-05T16:49:34.039945Z"
    },
    "id": "9PepPt_CL94x"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(999999)\n",
    "train = pd.read_csv('raw_data/fulltrain.csv', header = None, names=['class','text'])\n",
    "X_train = train['text']\n",
    "y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:34.935720Z",
     "start_time": "2024-03-05T16:49:34.929618Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sCT1xI_yXFJO",
    "outputId": "172bcde2-37a1-40c2-e329-f0152f49ab50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      1  A little less than a decade ago, hockey fans w...\n",
       "1      1  The writers of the HBO series The Sopranos too...\n",
       "2      1  Despite claims from the TV news outlet to offe...\n",
       "3      1  After receiving 'subpar' service and experienc...\n",
       "4      1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:35.839149Z",
     "start_time": "2024-03-05T16:49:35.784315Z"
    },
    "id": "-FcMBozxWAvz"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"raw_data/balancedtest.csv\", header = None, names=['class','text'])\n",
    "X_test = test['text']\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:36.665109Z",
     "start_time": "2024-03-05T16:49:36.648989Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s5befmSMXN8N",
    "outputId": "c1aef16d-ccb9-4036-f8af-1a6c9d16c035"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>When so many actors seem content to churn out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In what football insiders are calling an unex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>In a freak accident following Game 3 of the N....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>North Koreas official news agency announced to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The former Alaska Governor Sarah Palin would b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      1  When so many actors seem content to churn out ...\n",
       "1      1   In what football insiders are calling an unex...\n",
       "2      1  In a freak accident following Game 3 of the N....\n",
       "3      1  North Koreas official news agency announced to...\n",
       "4      1  The former Alaska Governor Sarah Palin would b..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WOxbEhspgUT"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:47.137182Z",
     "start_time": "2024-03-05T16:49:37.686948Z"
    },
    "id": "NKfM8O-nbbpJ"
   },
   "outputs": [],
   "source": [
    "def tfidf(X_train, X_test):\n",
    "\n",
    "  tfidf_baseline = TfidfVectorizer(ngram_range=(1,1), max_features = 10000)\n",
    "\n",
    "  X_train_tfidf = tfidf_baseline.fit_transform(X_train)\n",
    "\n",
    "  X_test_tfidf = tfidf_baseline.transform(X_test)\n",
    "\n",
    "  return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train_tfidf, y_train, X_test_tfidf, y_test):\n",
    "\n",
    "  LR_classifier = LogisticRegression(random_state = 42, max_iter=1000).fit(X_train_tfidf, y_train)\n",
    "\n",
    "  y_pred_lr = LR_classifier.predict(X_test_tfidf)\n",
    "\n",
    "  print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "  return y_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:53.567610Z",
     "start_time": "2024-03-05T16:49:47.138293Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDCcR3tOpJ-e",
    "outputId": "c1bc4bd9-bf63-4b1a-902b-147b1c243360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.79      0.82       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.56      0.83      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.71      3000\n",
      "weighted avg       0.76      0.73      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - baseline\n",
    "y_pred_lr = LR(X_train_tfidf, y_train, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(X_train_tfidf, y_train, X_test_tfidf, y_test):\n",
    "\n",
    "  nb_classifier = ComplementNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "  y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "  print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "  return y_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:53.621308Z",
     "start_time": "2024-03-05T16:49:53.568257Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQyWjGLUxREy",
    "outputId": "e4827d40-70fe-44b0-ecd2-9c271deaf5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.61      0.61       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.68      0.67      0.66      3000\n",
      "weighted avg       0.68      0.67      0.66      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NB - baseline\n",
    "y_pred_nb = NB(X_train_tfidf, y_train, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITNfwpWkt1OI"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6Yrnd2f_y5W"
   },
   "source": [
    "### Lemmatization with POS Tagging\n",
    "(DON'T RUN AGAIN! It takes tooooo long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:49:53.621497Z",
     "start_time": "2024-03-05T16:49:53.605689Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E3t6cQp1r-N",
    "outputId": "45aad408-e2fc-4eea-d48b-c4cd161199bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/stella/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to lemmatize each word with its POS tag\n",
    "\n",
    "# POS_TAGGER_FUNCTION : TYPE 1\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_with_pos(tokens):\n",
    "  # tokenize the sentence and find the POS tag for each token\n",
    "  pos_tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "  # print(pos_tagged)\n",
    "\n",
    "  wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "  # print(wordnet_tagged)\n",
    "\n",
    "  lemmatized_sentence = []\n",
    "  for word, tag in wordnet_tagged:\n",
    "      if tag is None:\n",
    "          # if there is no available tag, append the token as is\n",
    "          lemmatized_sentence.append(word)\n",
    "      else:\n",
    "          # else use the tag to lemmatize the token\n",
    "          lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "  # lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "\n",
    "  # print(lemmatized_sentence)\n",
    "  return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:00:54.576560Z",
     "start_time": "2024-03-05T16:49:53.615691Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-3cE9Qzt3zY",
    "outputId": "dd07285c-1ccd-41b5-c9d3-78d8174a7cb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/stella/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "100%|██████████| 48854/48854 [10:27<00:00, 77.91it/s] \n",
      "100%|██████████| 3000/3000 [00:33<00:00, 88.88it/s] \n"
     ]
    }
   ],
   "source": [
    "# Start preprocessing\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def preprocessing(data):\n",
    "  data_clean = []\n",
    "  for sentence in tqdm(data):\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Remove punctuation and number\n",
    "    tokens = [w for w in tokens if (not w in punc) and (not w.isdigit())]\n",
    "\n",
    "    # Spell check\n",
    "    # Taking too long time for each sentence, not practical to be used\n",
    "    # tokens = [spell.correction(w) for w in tokens]\n",
    "    # tokens = [w for w in tokens if w is not None and len(w) > 0]\n",
    "\n",
    "    # Lemmatization based on tagging\n",
    "    tokens = lemmatize_with_pos(tokens)\n",
    "\n",
    "    data_clean.append((' ').join(tokens))\n",
    "  return data_clean\n",
    "\n",
    "X_train_clean = preprocessing(X_train)\n",
    "X_test_clean = preprocessing(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:04:47.789779Z",
     "start_time": "2024-03-05T17:04:45.983859Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def write_to_csv(X_train_clean, X_test_clean):\n",
    "    with open('raw_data/X_train_clean.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for doc in X_train_clean:\n",
    "            writer.writerow([doc])\n",
    "\n",
    "    with open('raw_data/X_test_clean.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for doc in X_test_clean:\n",
    "            writer.writerow([doc])\n",
    "\n",
    "# Uncomment if you want to save X_train_clean and X_test_clean\n",
    "# write_to_csv(X_train_clean, X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:04:53.998277Z",
     "start_time": "2024-03-05T17:04:53.082771Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_from_file():\n",
    "    a_df = pd.read_csv('raw_data/X_train_clean.csv', header=None, dtype=str)\n",
    "    a = a_df[0].values\n",
    "    \n",
    "    b_df = pd.read_csv('raw_data/X_test_clean.csv', header=None, dtype=str)\n",
    "    b = b_df[0].values\n",
    "    return a, b\n",
    "\n",
    "# Uncomment if you want to read from file\n",
    "a, b = read_from_file()\n",
    "X_train_clean, X_test_clean = a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:05:11.041172Z",
     "start_time": "2024-03-05T17:04:55.869549Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nH-JuFWdzqHa",
    "outputId": "1e641367-5188-4e56-8a83-b04dbde46ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.84      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.75      0.74      3000\n",
      "weighted avg       0.77      0.74      0.74      3000\n"
     ]
    }
   ],
   "source": [
    "X_train_clean_tfidf, X_test_clean_tfidf = tfidf(X_train_clean, X_test_clean)\n",
    "\n",
    "_ = LR(X_train_clean_tfidf, y_train, X_test_clean_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:05:12.655783Z",
     "start_time": "2024-03-05T17:05:12.605867Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu2641T-HNd3",
    "outputId": "ba6f10d5-8b1f-4365-be7e-11ca479109bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.65      0.51      0.57       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ],
   "source": [
    "_ = NB(X_train_clean_tfidf, y_train, X_test_clean_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stopwords, duplicates, and contradicting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:06:48.406043Z",
     "start_time": "2024-03-05T17:05:14.905065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48652/48652 [01:26<00:00, 564.82it/s] \n",
      "100%|██████████| 2990/2990 [00:04<00:00, 606.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def lowercase(text): #trivial casefolding\n",
    "    return text.lower()\n",
    "\n",
    "#Obtain set of stopwords from nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    data_removed_stopwords = []\n",
    "    for sentence in tqdm(data):\n",
    "        #tokenize sentence into words\n",
    "        words = word_tokenize(sentence)\n",
    "        \n",
    "        #remove word if found in set of stopwords\n",
    "        words_wo_stopwords = [word for word in words if word.lower() not in stop_words]\n",
    "        \n",
    "        data_removed_stopwords.append(' '.join(words_wo_stopwords))\n",
    "    return data_removed_stopwords\n",
    "\n",
    "def remove_dupes(data):\n",
    "    #use pandas to drop duplicates, only removes those with equal values in both class and text columns\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "def remove_contradictions(data):\n",
    "    #group by text and filter groups with more than one unique label(contradicting labels)\n",
    "    contradictions = data.groupby('text').filter(lambda x: x['class'].nunique() > 1)\n",
    "    \n",
    "    #remove all texts with contradicting labels since we do not know which is the correct label\n",
    "    return data[~data['text'].isin(contradictions['text'])]\n",
    "\n",
    "def preprocess2(data):\n",
    "    processed_data = remove_dupes(data)\n",
    "    processed_data = remove_contradictions(processed_data)\n",
    "    processed_data['text'] = remove_stopwords(processed_data['text'])\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "train_clean2 = preprocess2(train)    \n",
    "test_clean2 = preprocess2(test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:06:54.749892Z",
     "start_time": "2024-03-05T17:06:48.424600Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_clean2 = train_clean2['text']\n",
    "y_train_clean2 = train_clean2['class']\n",
    "X_test_clean2 = test_clean2['text']\n",
    "y_test_clean2 = test_clean2['class']\n",
    "\n",
    "X_train_clean2_tfidf, X_test_clean2_tfidf = tfidf(X_train_clean2, X_test_clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:06:58.232005Z",
     "start_time": "2024-03-05T17:06:54.750452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.74      0.79       745\n",
      "           2       0.79      0.42      0.55       750\n",
      "           3       0.57      0.83      0.67       747\n",
      "           4       0.81      0.91      0.86       748\n",
      "\n",
      "    accuracy                           0.73      2990\n",
      "   macro avg       0.75      0.73      0.72      2990\n",
      "weighted avg       0.75      0.73      0.72      2990\n"
     ]
    }
   ],
   "source": [
    "_ = LR(X_train_clean2_tfidf, y_train_clean2, X_test_clean2_tfidf, y_test_clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:06:58.286818Z",
     "start_time": "2024-03-05T17:06:58.232950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60       745\n",
      "           2       0.61      0.45      0.52       750\n",
      "           3       0.61      0.92      0.73       747\n",
      "           4       0.87      0.67      0.76       748\n",
      "\n",
      "    accuracy                           0.66      2990\n",
      "   macro avg       0.67      0.66      0.65      2990\n",
      "weighted avg       0.67      0.66      0.65      2990\n"
     ]
    }
   ],
   "source": [
    "_ = NB(X_train_clean2_tfidf, y_train_clean2, X_test_clean2_tfidf, y_test_clean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTufYR0Gt4Wi"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:08:08.491871Z",
     "start_time": "2024-03-05T17:06:58.330465Z"
    },
    "id": "h4_ImWMZt6Ru"
   },
   "outputs": [],
   "source": [
    "# Text Subjectivity (w/o preprocessing)\n",
    "from textblob import TextBlob\n",
    "\n",
    "def subjectivity(data, tf_idf):\n",
    "    # new_data = data.copy()\n",
    "    new_data = data\n",
    "    new_data['psycho-linguistic'] = new_data[\"text\"].apply(lambda x: TextBlob(x).sentiment)\n",
    "    new_data['subjectivity'] = new_data['psycho-linguistic'].apply(lambda x: x[1])\n",
    "    tfidf_df = pd.DataFrame(tf_idf.toarray())\n",
    "    subject_df = pd.merge(tfidf_df, new_data['subjectivity'],left_index=True, right_index=True)\n",
    "    subject_df.columns = subject_df.columns.astype(str)\n",
    "    return subject_df\n",
    "\n",
    "train_subject_df = subjectivity(train, X_train_tfidf)\n",
    "test_subject_df = subjectivity(test, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:09:11.390660Z",
     "start_time": "2024-03-05T17:08:08.493418Z"
    },
    "id": "eqxPbQkservd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.57      0.82      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.72      3000\n",
      "weighted avg       0.76      0.73      0.72      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_subject_df, y_train, test_subject_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:09:13.136870Z",
     "start_time": "2024-03-05T17:09:11.435035Z"
    },
    "id": "qLCfOSineuZA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.68      0.67      0.66      3000\n",
      "weighted avg       0.68      0.67      0.66      3000\n"
     ]
    }
   ],
   "source": [
    "_ = NB(train_subject_df, y_train, test_subject_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:10:22.321745Z",
     "start_time": "2024-03-05T17:09:13.137714Z"
    },
    "id": "Z8wmIXUvewcx"
   },
   "outputs": [],
   "source": [
    "# Text Subjectivity (with preprocessing)\n",
    "train_clean_subject_df = subjectivity(train, X_train_clean_tfidf)\n",
    "test_clean_subject_df = subjectivity(test, X_test_clean_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:11:14.280845Z",
     "start_time": "2024-03-05T17:10:22.345631Z"
    },
    "id": "Oz5HO9tEey_y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.83      0.84       750\n",
      "           2       0.83      0.40      0.54       750\n",
      "           3       0.58      0.83      0.69       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_clean_subject_df, y_train, test_clean_subject_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:11:16.446900Z",
     "start_time": "2024-03-05T17:11:14.310628Z"
    },
    "id": "3Uyp0kzUe1V_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.64      0.51      0.57       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.87      0.65      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ],
   "source": [
    "_ = NB(train_clean_subject_df, y_train, test_clean_subject_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer\n",
    "We will adjust the possible parameters, i.e. n_grams, max_features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram: 1, max_feature: 10000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.84      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.75      0.74      3000\n",
      "weighted avg       0.77      0.74      0.74      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.65      0.51      0.57       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n",
      "\n",
      "n_gram: 1, max_feature: 20000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.82      0.83       750\n",
      "           2       0.85      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.78      0.75      0.74      3000\n",
      "weighted avg       0.78      0.75      0.74      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.61      0.61       750\n",
      "           2       0.63      0.48      0.55       750\n",
      "           3       0.62      0.92      0.74       750\n",
      "           4       0.88      0.65      0.75       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.66      3000\n",
      "weighted avg       0.69      0.67      0.66      3000\n",
      "\n",
      "n_gram: 1, max_feature: None\n",
      "Number of features: 220626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.81      0.83       750\n",
      "           2       0.84      0.41      0.56       750\n",
      "           3       0.59      0.84      0.70       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.53      0.59       750\n",
      "           2       0.60      0.12      0.21       750\n",
      "           3       0.39      0.99      0.56       750\n",
      "           4       0.95      0.44      0.60       750\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.65      0.52      0.49      3000\n",
      "weighted avg       0.65      0.52      0.49      3000\n",
      "\n",
      "n_gram: 2, max_feature: 10000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.75      0.80       750\n",
      "           2       0.83      0.35      0.49       750\n",
      "           3       0.55      0.83      0.66       750\n",
      "           4       0.76      0.92      0.83       750\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.75      0.71      0.69      3000\n",
      "weighted avg       0.75      0.71      0.69      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.61      0.61       750\n",
      "           2       0.64      0.46      0.54       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.82      0.68      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.68      0.67      0.66      3000\n",
      "weighted avg       0.68      0.67      0.66      3000\n",
      "\n",
      "n_gram: 2, max_feature: 20000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.78      0.81       750\n",
      "           2       0.84      0.34      0.48       750\n",
      "           3       0.56      0.83      0.67       750\n",
      "           4       0.77      0.92      0.84       750\n",
      "\n",
      "    accuracy                           0.72      3000\n",
      "   macro avg       0.76      0.72      0.70      3000\n",
      "weighted avg       0.76      0.72      0.70      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.64      0.63       750\n",
      "           2       0.64      0.47      0.54       750\n",
      "           3       0.64      0.91      0.75       750\n",
      "           4       0.84      0.69      0.76       750\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.69      0.68      0.67      3000\n",
      "weighted avg       0.69      0.68      0.67      3000\n",
      "\n",
      "n_gram: 2, max_feature: None\n",
      "Number of features: 4774152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.81      0.82       750\n",
      "           2       0.85      0.34      0.48       750\n",
      "           3       0.58      0.87      0.70       750\n",
      "           4       0.80      0.90      0.85       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.77      0.73      0.71      3000\n",
      "weighted avg       0.77      0.73      0.71      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.12      0.20       750\n",
      "           2       0.77      0.01      0.03       750\n",
      "           3       0.28      1.00      0.43       750\n",
      "           4       1.00      0.20      0.33       750\n",
      "\n",
      "    accuracy                           0.33      3000\n",
      "   macro avg       0.69      0.33      0.25      3000\n",
      "weighted avg       0.69      0.33      0.25      3000\n",
      "\n",
      "n_gram: 3, max_feature: 10000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.75      0.80       750\n",
      "           2       0.82      0.33      0.47       750\n",
      "           3       0.55      0.83      0.66       750\n",
      "           4       0.75      0.92      0.83       750\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.75      0.71      0.69      3000\n",
      "weighted avg       0.75      0.71      0.69      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.63      0.62       750\n",
      "           2       0.64      0.42      0.51       750\n",
      "           3       0.63      0.92      0.75       750\n",
      "           4       0.81      0.68      0.74       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.67      0.66      0.65      3000\n",
      "weighted avg       0.67      0.66      0.65      3000\n",
      "\n",
      "n_gram: 3, max_feature: 20000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.77      0.81       750\n",
      "           2       0.84      0.32      0.46       750\n",
      "           3       0.55      0.82      0.66       750\n",
      "           4       0.76      0.92      0.83       750\n",
      "\n",
      "    accuracy                           0.71      3000\n",
      "   macro avg       0.75      0.71      0.69      3000\n",
      "weighted avg       0.75      0.71      0.69      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.66      0.63       750\n",
      "           2       0.66      0.45      0.53       750\n",
      "           3       0.66      0.89      0.76       750\n",
      "           4       0.82      0.71      0.76       750\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.68      0.68      0.67      3000\n",
      "weighted avg       0.68      0.68      0.67      3000\n",
      "\n",
      "n_gram: 3, max_feature: None\n",
      "Number of features: 18739817\n"
     ]
    }
   ],
   "source": [
    "# All this need Kfold cross validation in the future\n",
    "\n",
    "n_grams = [1, 2, 3, 4]\n",
    "max_features = [10000, 20000, None]\n",
    "def tfidf(X_train, X_test, n_gram, max_feature):\n",
    "  tfidf_baseline = TfidfVectorizer(ngram_range=(1,n_gram), max_features = max_feature)\n",
    "  X_train_tfidf = tfidf_baseline.fit_transform(X_train)\n",
    "  X_test_tfidf = tfidf_baseline.transform(X_test)\n",
    "  return X_train_tfidf, X_test_tfidf\n",
    "\n",
    "for n_gram in n_grams:\n",
    "  for max_feature in max_features:\n",
    "    X_train_tfidf, X_test_tfidf = tfidf(X_train_clean, X_test_clean, n_gram, max_feature)\n",
    "    print(f\"n_gram: {n_gram}, max_feature: {max_feature}\")\n",
    "    num_features = X_train_tfidf.shape[1]\n",
    "    if max_feature is None:\n",
    "      print(f\"Number of features: {num_features}\")\n",
    "    _ = LR(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "    _ = NB(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "# Ran until n_gram = 3 for 30min ><"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "#### GloVe\n",
    "- Download from https://nlp.stanford.edu/projects/glove/\n",
    "- Used Wikipedia 2014 + Gigaword 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file_path):\n",
    "    glove_model = {}\n",
    "    with open(glove_file_path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            # embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            try:\n",
    "                coefs = np.asarray(split_line[1:], dtype='float32')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            glove_model[word] = coefs\n",
    "    return glove_model\n",
    "\n",
    "glove_model = load_glove_model(\"glove.6B/glove.6B.300d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "X_train_processed = X_train.apply(preprocess_text)\n",
    "X_test_processed = X_test.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc, model):\n",
    "    # Filter out words that are not in the embedding\n",
    "    embeddings = [model[word] for word in doc if word in model]\n",
    "    if not embeddings:\n",
    "        # If no words in the document are in the model, return a vector of zeros\n",
    "        return np.zeros(next(iter(model.values())).shape)\n",
    "    # Average the embeddings\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "X_train_vectors = np.array([document_vector(doc, glove_model) for doc in X_train_processed])\n",
    "X_test_vectors = np.array([document_vector(doc, glove_model) for doc in X_test_processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.61      0.66       750\n",
      "           2       0.64      0.44      0.52       750\n",
      "           3       0.49      0.65      0.56       750\n",
      "           4       0.73      0.82      0.77       750\n",
      "\n",
      "    accuracy                           0.63      3000\n",
      "   macro avg       0.64      0.63      0.63      3000\n",
      "weighted avg       0.64      0.63      0.63      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GloVe embeddings + Logistic Regression\n",
    "_ = LR(X_train_vectors, y_train, X_test_vectors, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.34      0.34       750\n",
      "           2       0.46      0.81      0.58       750\n",
      "           3       0.73      0.40      0.52       750\n",
      "           4       0.76      0.51      0.61       750\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.57      0.51      0.51      3000\n",
      "weighted avg       0.57      0.51      0.51      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "_ = classifier.fit(X_train_vectors, y_train)\n",
    "y_pred = classifier.predict(X_test_vectors)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hedging word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:28:24.733933Z",
     "start_time": "2024-03-05T17:27:58.208190Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hedging Word Count\n",
    "# Reference: all 176 hedging words in hedges.txt are from https://github.com/words/hedges\n",
    "import re\n",
    "\n",
    "def fetch_hedging_regex(filename='hedges.txt'):\n",
    "    hedges = []\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    for l in lines:\n",
    "        hedges.append(l.strip())\n",
    "    hedges_re = \"(?:^|\\W)(\" + \"|\".join(hedges) + \")(?:$|\\W)\"\n",
    "    return hedges_re\n",
    "\n",
    "def hedges(x, hedges_re):\n",
    "    res = re.findall(hedges_re, x.lower())\n",
    "    counts = sum(1 for s in res if s != '')\n",
    "    if counts > 0:\n",
    "        return 1 \n",
    "    return 0\n",
    "\n",
    "def hedging_word_count(data, tf_idf, hedge_re):\n",
    "    new_data = data.copy()\n",
    "    new_data[\"hedges\"] = new_data.loc[:, \"text\"].apply(hedges, hedges_re=hedge_re)\n",
    "    tfidf_df = pd.DataFrame(tf_idf.toarray())\n",
    "    hedged_df = pd.merge(tfidf_df, new_data['hedges'],left_index=True, right_index=True)\n",
    "    hedged_df.columns = hedged_df.columns.astype(str)\n",
    "    return hedged_df\n",
    "\n",
    "hedges_re = fetch_hedging_regex()\n",
    "train_hedge_df = hedging_word_count(train, X_train_tfidf, hedges_re)\n",
    "test_hedge_df = hedging_word_count(test, X_test_tfidf, hedges_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:29:12.802388Z",
     "start_time": "2024-03-05T17:28:24.756603Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.82      0.83       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.57      0.82      0.68       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.72      3000\n",
      "weighted avg       0.76      0.73      0.72      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_hedge_df, y_train, test_hedge_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:29:15.025973Z",
     "start_time": "2024-03-05T17:29:12.842389Z"
    },
    "id": "V_EZcIXQfD-t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62       750\n",
      "           2       0.62      0.46      0.53       750\n",
      "           3       0.62      0.93      0.74       750\n",
      "           4       0.88      0.67      0.76       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.66      3000\n",
      "weighted avg       0.69      0.67      0.66      3000\n"
     ]
    }
   ],
   "source": [
    "_ = NB(train_hedge_df, y_train, test_hedge_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:29:40.772374Z",
     "start_time": "2024-03-05T17:29:15.066556Z"
    },
    "id": "rYz1yM-ffFyo"
   },
   "outputs": [],
   "source": [
    "# Hedging Word Count (with preprocessing)\n",
    "train_clean_hedge_df = hedging_word_count(train, X_train_clean_tfidf, hedges_re)\n",
    "test_clean_hedge_df = hedging_word_count(test, X_test_clean_tfidf, hedges_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:30:46.644960Z",
     "start_time": "2024-03-05T17:29:40.795476Z"
    },
    "id": "mYjo7t8AfIMg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.83      0.84       750\n",
      "           2       0.83      0.41      0.54       750\n",
      "           3       0.59      0.82      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_clean_hedge_df, y_train, test_clean_hedge_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:30:48.552354Z",
     "start_time": "2024-03-05T17:30:46.675254Z"
    },
    "id": "GzySa4unfL_F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.61      0.61       750\n",
      "           2       0.64      0.51      0.57       750\n",
      "           3       0.63      0.91      0.75       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.69      0.67      0.67      3000\n",
      "weighted avg       0.69      0.67      0.67      3000\n"
     ]
    }
   ],
   "source": [
    "_ = NB(train_clean_hedge_df, y_train, test_clean_hedge_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/james/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T13:38:37.122924Z",
     "start_time": "2024-03-03T13:38:37.121971Z"
    },
    "id": "HgSb6hNwfNmO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_features(data, tf_idf):\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    new_data['sentiments'] = new_data['text'].apply(lambda x: sia.polarity_scores(x))\n",
    "    new_data['compound'] = new_data['sentiments'].apply(lambda x: x['compound'])\n",
    "    tfidf_df = pd.DataFrame(tf_idf.toarray())\n",
    "    sentiment_df = pd.merge(tfidf_df, new_data['compound'], left_index=True, right_index=True)\n",
    "    sentiment_df.columns = sentiment_df.columns.astype(str)\n",
    "    \n",
    "    return sentiment_df\n",
    "\n",
    "train_sentiment_df = sentiment_features(train, X_train_tfidf)\n",
    "test_sentiment_df = sentiment_features(test, X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.80      0.82       750\n",
      "           2       0.82      0.37      0.52       750\n",
      "           3       0.56      0.83      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.72      3000\n",
      "weighted avg       0.76      0.73      0.72      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_sentiment_df, y_train, test_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.64      0.62       750\n",
      "           2       0.62      0.45      0.52       750\n",
      "           3       0.62      0.92      0.74       750\n",
      "           4       0.88      0.66      0.75       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.68      0.66      0.66      3000\n",
      "weighted avg       0.68      0.66      0.66      3000\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Scores may be negative so NB will not work. For NB, I have added a constant to the sentiment scores to make them all positive.\n",
    "min_compound_train = train_sentiment_df['compound'].min()\n",
    "min_compound_test = test_sentiment_df['compound'].min()\n",
    "min_compound = min(min_compound_train, min_compound_test)\n",
    "\n",
    "if min_compound < 0:\n",
    "    adjustment = abs(min_compound)\n",
    "    train_sentiment_df['compound'] += adjustment\n",
    "    test_sentiment_df['compound'] += adjustment\n",
    "\n",
    "_ = NB(train_sentiment_df, y_train, test_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Preprocessing\n",
    "train_clean_sentiment_df = sentiment_features(train, X_train_clean_tfidf)\n",
    "test_clean_sentiment_df = sentiment_features(test, X_test_clean_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.81      0.82       750\n",
      "           2       0.84      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.73      3000\n",
      "weighted avg       0.77      0.74      0.73      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_clean_sentiment_df, y_train, test_clean_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       750\n",
      "           2       0.63      0.48      0.54       750\n",
      "           3       0.62      0.91      0.74       750\n",
      "           4       0.87      0.64      0.74       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.68      0.66      0.66      3000\n",
      "weighted avg       0.68      0.66      0.66      3000\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Scores may be negative so NB will not work. For NB, I have added a constant to the sentiment scores to make them all positive.\n",
    "min_clean_compound_train = train_clean_sentiment_df['compound'].min()\n",
    "min_clean_compound_test = test_clean_sentiment_df['compound'].min()\n",
    "min_clean_compound = min(min_clean_compound_train, min_clean_compound_test)\n",
    "\n",
    "if min_clean_compound < 0:\n",
    "    adjustment = abs(min_clean_compound)\n",
    "    train_clean_sentiment_df['compound'] += adjustment\n",
    "    test_clean_sentiment_df['compound'] += adjustment\n",
    "    \n",
    "_ = NB(train_clean_sentiment_df, y_train, test_clean_sentiment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sentence Length\n",
    "- Number of quotations\n",
    "- Count of word types:\n",
    "    - Numbers\n",
    "    - Proper nouns\n",
    "    - Conjunctions\n",
    "    - Superlatives\n",
    "    - 1st / 3rd pronoun counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhizhouhuang/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85       750\n",
      "           2       0.84      0.44      0.58       750\n",
      "           3       0.60      0.82      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.78      0.75      0.74      3000\n",
      "weighted avg       0.78      0.75      0.74      3000\n",
      "\n",
      "Time taken for Sentence Length on Not Processed dataset: 93.36047506332397 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.79      0.82       750\n",
      "           2       0.81      0.37      0.51       750\n",
      "           3       0.56      0.83      0.67       750\n",
      "           4       0.81      0.92      0.86       750\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.76      0.73      0.71      3000\n",
      "weighted avg       0.76      0.73      0.71      3000\n",
      "\n",
      "Time taken for Count Quotations on Not Processed dataset: 7.237422943115234 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.82      0.84       750\n",
      "           2       0.83      0.44      0.57       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.75      3000\n",
      "   macro avg       0.77      0.75      0.74      3000\n",
      "weighted avg       0.77      0.75      0.74      3000\n",
      "\n",
      "Time taken for Count Numbers on Not Processed dataset: 57.37210702896118 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhizhouhuang/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.84      0.43      0.56       750\n",
      "           3       0.58      0.80      0.68       750\n",
      "           4       0.79      0.91      0.85       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.76      0.74      0.73      3000\n",
      "weighted avg       0.76      0.74      0.73      3000\n",
      "\n",
      "Time taken for Count Proper Nouns on Not Processed dataset: 672.8190791606903 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83       750\n",
      "           2       0.82      0.42      0.56       750\n",
      "           3       0.59      0.83      0.69       750\n",
      "           4       0.81      0.91      0.86       750\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.74      0.74      3000\n",
      "weighted avg       0.77      0.74      0.74      3000\n",
      "\n",
      "Time taken for Count Conjunctions on Not Processed dataset: 667.076840877533 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Processed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     X_train_enhanced \u001b[38;5;241m=\u001b[39m \u001b[43madd_custom_feature_to_tfidf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     X_test_enhanced \u001b[38;5;241m=\u001b[39m add_custom_feature_to_tfidf(X_test, X_test_tfidf, feature_matrix)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36madd_custom_feature_to_tfidf\u001b[0;34m(data, tfidf_matrix, feature_extraction_func)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_custom_feature_to_tfidf\u001b[39m(data, tfidf_matrix, feature_extraction_func):\n\u001b[0;32m---> 18\u001b[0m     custom_feature \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_extraction_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     custom_feature_sparse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(custom_feature)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     enhanced_tfidf_matrix \u001b[38;5;241m=\u001b[39m hstack([tfidf_matrix, custom_feature_sparse])\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m, in \u001b[0;36mcount_superlatives\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_superlatives\u001b[39m(text):\n\u001b[0;32m---> 44\u001b[0m     tagged \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     superlatives \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word, pos \u001b[38;5;129;01min\u001b[39;00m tagged \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJJS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(superlatives)\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/nltk/tag/__init__.py:166\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mtag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/nltk/tag/__init__.py:123\u001b[0m, in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens: expected a list of strings, got a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tagset:  \u001b[38;5;66;03m# Maps to the specified tagset.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/nltk/tag/perceptron.py:186\u001b[0m, in \u001b[0;36mPerceptronTagger.tag\u001b[0;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[1;32m    182\u001b[0m tag, conf \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagdict\u001b[38;5;241m.\u001b[39mget(word), \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m use_tagdict \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tag:\n\u001b[0;32m--> 186\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     tag, conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(features, return_conf)\n\u001b[1;32m    188\u001b[0m output\u001b[38;5;241m.\u001b[39mappend((word, tag, conf) \u001b[38;5;28;01mif\u001b[39;00m return_conf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (word, tag))\n",
      "File \u001b[0;32m~/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/nltk/tag/perceptron.py:295\u001b[0m, in \u001b[0;36mPerceptronTagger._get_features\u001b[0;34m(self, i, word, context, prev, prev2)\u001b[0m\n\u001b[1;32m    293\u001b[0m features \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# It's useful to have a constant feature, which acts sort of like a prior\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m add(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m, word[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:])\n\u001b[1;32m    297\u001b[0m add(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi pref1\u001b[39m\u001b[38;5;124m\"\u001b[39m, word[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Again, all this need Kfold cross validation in the future\n",
    "\n",
    "# Count sentence length\n",
    "# Count number of quotations\n",
    "# Count of word types: Numbers, Proper nouns, Conjunctions, Superlatives, 1st / 3rd pronoun counts (w/o preprocessing)\n",
    "# Count of booster words (with preprocessing)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from scipy.sparse import hstack\n",
    "import time\n",
    "\n",
    "# Uncomment if you have not downloaded the 'punkt' and 'averaged_perceptron_tagger' packages\n",
    "# nltk.download('punkt') \n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def add_custom_feature_to_tfidf(data, tfidf_matrix, feature_extraction_func):\n",
    "    custom_feature = data.apply(feature_extraction_func)\n",
    "    custom_feature_sparse = np.array(custom_feature).reshape(-1, 1)\n",
    "    enhanced_tfidf_matrix = hstack([tfidf_matrix, custom_feature_sparse])\n",
    "    return enhanced_tfidf_matrix\n",
    "\n",
    "# Feature extraction functions\n",
    "def count_sentence_length(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "def count_quotations(text):\n",
    "    return text.count('\"')\n",
    "\n",
    "def count_numbers(text):\n",
    "    return len(re.findall(r'\\d+', text))\n",
    "\n",
    "def count_proper_nouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    proper_nouns = [word for word, pos in tagged if pos == 'NNP']\n",
    "    return len(proper_nouns)\n",
    "\n",
    "def count_conjunctions(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    conjunctions = [word for word, pos in tagged if pos == 'CC']\n",
    "    return len(conjunctions)\n",
    "\n",
    "def count_superlatives(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    superlatives = [word for word, pos in tagged if pos == 'JJS']\n",
    "    return len(superlatives)\n",
    "\n",
    "def count_1st_pronouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    first_pronouns = [word for word, pos in tagged if pos == 'PRP' and word.lower() in ['i', 'me', 'my', 'mine']]\n",
    "    return len(first_pronouns)\n",
    "\n",
    "def count_3rd_pronouns(text):\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    third_pronouns = [word for word, pos in tagged if pos == 'PRP' and word.lower() in \n",
    "                      ['he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'they', 'them', 'their', 'theirs']]\n",
    "    return len(third_pronouns)\n",
    "\n",
    "def count_booster_words(text):\n",
    "    booster_words = \"\"\"absolutely amazingly awfully completely considerably definitely entirely exceedingly\n",
    "                    extremely highly incredibly indeed quite really remarkably so terribly totally truly utterly very\"\"\"\n",
    "    booster_words = booster_words.split(\" \")\n",
    "    return len([word for word in text.split(\" \") if word in booster_words])\n",
    "\n",
    "# Evaluate the performance of the model with the custom features\n",
    "# For the purpose of comparison, we can just use the logistic regression model across all the custom features\n",
    "features_methods_dictionary =  {\n",
    "    \"Sentence Length\": count_sentence_length,\n",
    "    \"Count Quotations\": count_quotations,\n",
    "    \"Count Numbers\": count_numbers,\n",
    "    \"Count Proper Nouns\": count_proper_nouns,\n",
    "    \"Count Conjunctions\": count_conjunctions,\n",
    "    \"Count Superlatives\": count_superlatives,\n",
    "    \"Count 1st Pronouns\": count_1st_pronouns,\n",
    "    \"Count 3rd Pronouns\": count_3rd_pronouns,\n",
    "    \"Count Booster Words\": count_booster_words\n",
    "}\n",
    "\n",
    "training_datasets = {\n",
    "    \"Not Processed\": [X_train, X_train_tfidf, X_test, X_test_tfidf],\n",
    "    \"Processed\": [X_train_clean, X_train_clean_tfidf, X_test_clean, X_test_clean_tfidf]\n",
    "}\n",
    "for dataset_name , datasets in training_datasets.items():\n",
    "    X_train = datasets[0]\n",
    "    X_train_tfidf = datasets[1]\n",
    "    X_test = datasets[2]\n",
    "    X_test_tfidf = datasets[3]\n",
    "    for feature_name, feature_matrix in features_methods_dictionary.items():\n",
    "        time_start = time.time()\n",
    "        if dataset_name == \"Not Processed\":\n",
    "            X_train_enhanced = add_custom_feature_to_tfidf(X_train, X_train_tfidf, feature_matrix)\n",
    "            X_test_enhanced = add_custom_feature_to_tfidf(X_test, X_test_tfidf, feature_matrix)\n",
    "        else:\n",
    "            X_train_enhanced = add_custom_feature_to_tfidf(X_train, X_train_tfidf, feature_matrix)\n",
    "            X_test_enhanced = add_custom_feature_to_tfidf(X_test, X_test_tfidf, feature_matrix)\n",
    "        _ = LR(X_train_enhanced, y_train, X_test_enhanced, y_test)\n",
    "        time_end = time.time()\n",
    "        print(f\"Time taken for {feature_name} on {dataset_name} dataset: {time_end - time_start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_features(train_df, test_df):\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_df)\n",
    "    test_scaled = scaler.transform(test_df)\n",
    "    \n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=train_df.columns)\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=test_df.columns)\n",
    "    \n",
    "    return train_scaled_df, test_scaled_df\n",
    "\n",
    "train_length_scaled_df, test_length_scaled_df = scale_features(train_length_df, test_length_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.74      0.79       750\n",
      "           2       0.73      0.40      0.51       750\n",
      "           3       0.57      0.73      0.64       750\n",
      "           4       0.74      0.94      0.82       750\n",
      "\n",
      "    accuracy                           0.70      3000\n",
      "   macro avg       0.72      0.70      0.69      3000\n",
      "weighted avg       0.72      0.70      0.69      3000\n"
     ]
    }
   ],
   "source": [
    "_ = LR(train_length_scaled_df, y_train, test_length_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.86      0.74       750\n",
      "           2       0.72      0.42      0.53       750\n",
      "           3       0.56      0.93      0.70       750\n",
      "           4       0.90      0.39      0.55       750\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.71      0.65      0.63      3000\n",
      "weighted avg       0.71      0.65      0.63      3000\n"
     ]
    }
   ],
   "source": [
    "# For some reason, after scaling sentence length can give negative values so I will just use NB with unscaled sentence length.\n",
    "\n",
    "_ = NB(train_length_df, y_train, test_length_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
