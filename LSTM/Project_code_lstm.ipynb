{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.8.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.25.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.25.1)\n",
      "Requirement already satisfied: pandas==2.1.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: pyspellchecker==0.8.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: scikit-learn==1.4.1.post1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.4.1.post1)\n",
      "Requirement already satisfied: tqdm==4.65.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.65.0)\n",
      "Requirement already satisfied: textblob in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.18.0.post0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas==2.1.1->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.10/site-packages (from scikit-learn==1.4.1.post1->-r requirements.txt (line 5)) (1.12.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.1.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhizhouhuang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/44/6b6tlgbd7z136wnf8vrdxjmw0000gn/T/ipykernel_20959/2908906817.py:28: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_path, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_filename = \"glove.6B.100d.txt\"\n",
    "# If you are running for the first time, uncomment the below 2 lines\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip glove*.zip\n",
    "glove_path = os.path.abspath(os.path.join(\".\", glove_filename))\n",
    "\n",
    "word2vec_output_file = glove_filename + \".word2vec\"\n",
    "\n",
    "glove2word2vec(glove_path, word2vec_output_file)\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(999999)\n",
    "train = pd.read_csv(\"raw_data/fulltrain.csv\", header=None, names=[\"class\", \"text\"])\n",
    "X_train = train[\"text\"]\n",
    "y_train = train[\"class\"]\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"raw_data/balancedtest.csv\", header=None, names=[\"class\", \"text\"])\n",
    "X_test = test[\"text\"]\n",
    "y_test = test[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "y_train_labeled = one_hot_encoder.fit_transform(\n",
    "    np.array(y_train).reshape(-1, 1)\n",
    ").toarray()\n",
    "y_test_labeled = one_hot_encoder.transform(np.array(y_test).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Word2VecVectorizer:\n",
    "    def __init__(self, model):\n",
    "        print(\"Loading in word vectors...\")\n",
    "        self.word_vectors = model\n",
    "        print(\"Finished loading in word vectors\")\n",
    "\n",
    "    def fit(self, data):\n",
    "        pass\n",
    "\n",
    "    def transform(self, data):\n",
    "        # determine the dimensionality of vectors\n",
    "        v = self.word_vectors.get_vector(\"queen\")\n",
    "        self.D = v.shape[0]\n",
    "\n",
    "        X = np.zeros((len(data), self.D * 3))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in tqdm(data):\n",
    "            tokens = nltk.word_tokenize(sentence.lower())\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    # throws KeyError if word not found\n",
    "                    vec = self.word_vectors.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = np.concatenate(\n",
    "                    (vecs.mean(axis=0), vecs.min(axis=0), vecs.max(axis=0))\n",
    "                )\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\n",
    "            \"Number of samples with no words found: %s / %s\" % (emptycount, len(data))\n",
    "        )\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [01:39<00:00, 489.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with no words found: 2 / 48854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_vectorizer = Word2VecVectorizer(word2vec_model)\n",
    "X_train_word2vec = word2vec_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:05<00:00, 532.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with no words found: 0 / 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# apply to test\n",
    "X_test_word2vec = word2vec_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48854, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_word2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "max_length = 1000\n",
    "vectorizer = layers.TextVectorization(\n",
    "    max_tokens=20000, output_sequence_length=max_length\n",
    ")\n",
    "vectorizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48854, 1000)\n",
      "tf.Tensor(\n",
      "[[   6  226  310 ...    0    0    0]\n",
      " [   2 3946    4 ...    0    0    0]], shape=(2, 1000), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "X_train_vector = vectorizer(X_train)\n",
    "X_test_vector = vectorizer(X_test)\n",
    "\n",
    "print(X_train_vector.shape)\n",
    "print(X_train_vector[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "glove_filename = \"glove.6B.\" + str(embedding_dim) + \"d.txt\"\n",
    "glove_path = os.path.abspath(os.path.join(\".\", glove_filename))\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(glove_path) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 19415 words (585 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20002, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in ./venv/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow-addons) (23.2)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in ./venv/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhizhouhuang/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m2,000,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m42,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044,652</span> (7.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,044,652\u001b[0m (7.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044,652</span> (7.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,044,652\u001b[0m (7.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 318ms/step - accuracy: 0.4001 - f1_score: 0.2545 - loss: 1.2451 - val_accuracy: 0.2803 - val_f1_score: 0.1534 - val_loss: 1.4864\n",
      "Epoch 2/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 308ms/step - accuracy: 0.4348 - f1_score: 0.2674 - loss: 1.1977 - val_accuracy: 0.4473 - val_f1_score: 0.3244 - val_loss: 1.3914\n",
      "Epoch 3/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 324ms/step - accuracy: 0.5637 - f1_score: 0.3715 - loss: 1.0362 - val_accuracy: 0.4653 - val_f1_score: 0.3401 - val_loss: 1.4503\n",
      "Epoch 4/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 347ms/step - accuracy: 0.6736 - f1_score: 0.5105 - loss: 0.7329 - val_accuracy: 0.4520 - val_f1_score: 0.3896 - val_loss: 2.3075\n",
      "Epoch 5/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 318ms/step - accuracy: 0.7773 - f1_score: 0.6813 - loss: 0.4891 - val_accuracy: 0.5250 - val_f1_score: 0.4779 - val_loss: 1.8568\n",
      "Epoch 6/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 340ms/step - accuracy: 0.8102 - f1_score: 0.7531 - loss: 0.3892 - val_accuracy: 0.6830 - val_f1_score: 0.6729 - val_loss: 1.9111\n",
      "Epoch 7/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 353ms/step - accuracy: 0.9370 - f1_score: 0.9318 - loss: 0.2054 - val_accuracy: 0.7213 - val_f1_score: 0.7191 - val_loss: 1.5956\n",
      "Epoch 8/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 347ms/step - accuracy: 0.9751 - f1_score: 0.9727 - loss: 0.0961 - val_accuracy: 0.6867 - val_f1_score: 0.6805 - val_loss: 2.0643\n",
      "Epoch 9/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 311ms/step - accuracy: 0.9860 - f1_score: 0.9845 - loss: 0.0578 - val_accuracy: 0.6953 - val_f1_score: 0.6846 - val_loss: 3.4175\n",
      "Epoch 10/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 333ms/step - accuracy: 0.9898 - f1_score: 0.9887 - loss: 0.0462 - val_accuracy: 0.7040 - val_f1_score: 0.6967 - val_loss: 2.9387\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.75       750\n",
      "           2       0.69      0.67      0.68       750\n",
      "           3       0.72      0.63      0.67       750\n",
      "           4       0.69      0.87      0.77       750\n",
      "\n",
      "    accuracy                           0.72      3000\n",
      "   macro avg       0.72      0.72      0.72      3000\n",
      "weighted avg       0.72      0.72      0.72      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 100\n",
    "epochs = 10\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(num_tokens, embedding_dim, input_length=max_length)\n",
    "embedding_layer.build()\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "# Adding Bidirectional LSTM layers\n",
    "x = LSTM(64)(x)\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "# x = Bidirectional(LSTM(64))(x)  # Adding Flatten layer to convert output to 2D tensor\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\", dtype=None\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = \"checkpoint_model_lstm_64.keras\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_vector,\n",
    "    y_train_labeled,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test_vector, y_test_labeled),\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "y_pred_inverse = one_hot_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m2,000,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,187,756</span> (8.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,187,756\u001b[0m (8.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,187,756</span> (8.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,187,756\u001b[0m (8.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1365s\u001b[0m 892ms/step - accuracy: 0.7544 - f1_score: 0.7383 - loss: 0.6312 - val_accuracy: 0.5920 - val_f1_score: 0.5631 - val_loss: 1.4156\n",
      "Epoch 2/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1410s\u001b[0m 923ms/step - accuracy: 0.9652 - f1_score: 0.9620 - loss: 0.1211 - val_accuracy: 0.5860 - val_f1_score: 0.5731 - val_loss: 1.3938\n",
      "Epoch 3/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1572s\u001b[0m 1s/step - accuracy: 0.9802 - f1_score: 0.9784 - loss: 0.0666 - val_accuracy: 0.6187 - val_f1_score: 0.6025 - val_loss: 1.9994\n",
      "Epoch 4/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1437s\u001b[0m 941ms/step - accuracy: 0.9926 - f1_score: 0.9918 - loss: 0.0300 - val_accuracy: 0.6150 - val_f1_score: 0.5947 - val_loss: 3.0107\n",
      "Epoch 5/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 874ms/step - accuracy: 0.9948 - f1_score: 0.9943 - loss: 0.0206 - val_accuracy: 0.6497 - val_f1_score: 0.6315 - val_loss: 2.4458\n",
      "Epoch 6/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1452s\u001b[0m 951ms/step - accuracy: 0.9962 - f1_score: 0.9958 - loss: 0.0168 - val_accuracy: 0.6337 - val_f1_score: 0.5983 - val_loss: 2.7180\n",
      "Epoch 7/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 905ms/step - accuracy: 0.9972 - f1_score: 0.9970 - loss: 0.0097 - val_accuracy: 0.6683 - val_f1_score: 0.6538 - val_loss: 2.2899\n",
      "Epoch 8/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1427s\u001b[0m 935ms/step - accuracy: 0.9970 - f1_score: 0.9968 - loss: 0.0104 - val_accuracy: 0.6147 - val_f1_score: 0.5969 - val_loss: 4.0087\n",
      "Epoch 9/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1399s\u001b[0m 916ms/step - accuracy: 0.9973 - f1_score: 0.9972 - loss: 0.0115 - val_accuracy: 0.6057 - val_f1_score: 0.5907 - val_loss: 3.8789\n",
      "Epoch 10/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1345s\u001b[0m 881ms/step - accuracy: 0.9983 - f1_score: 0.9982 - loss: 0.0066 - val_accuracy: 0.6417 - val_f1_score: 0.6227 - val_loss: 4.0173\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 185ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.78      0.78       750\n",
      "           2       0.76      0.66      0.70       750\n",
      "           3       0.55      0.34      0.42       750\n",
      "           4       0.59      0.90      0.72       750\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.67      0.67      0.65      3000\n",
      "weighted avg       0.67      0.67      0.65      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 100\n",
    "epochs = 10\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(num_tokens, embedding_dim, input_length=max_length)\n",
    "embedding_layer.build()\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "# Adding Bidirectional LSTM layers\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\", dtype=None\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = \"checkpoint_model_2_bi_lstm_64.keras\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_vector,\n",
    "    y_train_labeled,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test_vector, y_test_labeled),\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "y_pred_inverse = one_hot_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m2,000,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,085,196</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,085,196\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,085,196</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,085,196\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 499ms/step - accuracy: 0.8201 - f1_score: 0.8004 - loss: 0.4827 - val_accuracy: 0.5890 - val_f1_score: 0.5661 - val_loss: 1.3082\n",
      "Epoch 2/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 497ms/step - accuracy: 0.9763 - f1_score: 0.9743 - loss: 0.0705 - val_accuracy: 0.6187 - val_f1_score: 0.6033 - val_loss: 1.5458\n",
      "Epoch 3/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4999s\u001b[0m 3s/step - accuracy: 0.9925 - f1_score: 0.9920 - loss: 0.0243 - val_accuracy: 0.6103 - val_f1_score: 0.5979 - val_loss: 1.7963\n",
      "Epoch 4/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m769s\u001b[0m 504ms/step - accuracy: 0.9969 - f1_score: 0.9967 - loss: 0.0116 - val_accuracy: 0.6213 - val_f1_score: 0.5888 - val_loss: 1.9525\n",
      "Epoch 5/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 499ms/step - accuracy: 0.9986 - f1_score: 0.9985 - loss: 0.0051 - val_accuracy: 0.6003 - val_f1_score: 0.5911 - val_loss: 2.0958\n",
      "Epoch 6/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 505ms/step - accuracy: 0.9990 - f1_score: 0.9990 - loss: 0.0032 - val_accuracy: 0.6593 - val_f1_score: 0.6391 - val_loss: 1.8125\n",
      "Epoch 7/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 499ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0023 - val_accuracy: 0.6417 - val_f1_score: 0.6253 - val_loss: 2.0104\n",
      "Epoch 8/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 503ms/step - accuracy: 0.9995 - f1_score: 0.9994 - loss: 0.0019 - val_accuracy: 0.6537 - val_f1_score: 0.6444 - val_loss: 2.0445\n",
      "Epoch 9/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 501ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0015 - val_accuracy: 0.6397 - val_f1_score: 0.6216 - val_loss: 1.8825\n",
      "Epoch 10/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 504ms/step - accuracy: 0.9998 - f1_score: 0.9997 - loss: 8.3316e-04 - val_accuracy: 0.6630 - val_f1_score: 0.6547 - val_loss: 2.1191\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.75      0.81       750\n",
      "           2       0.74      0.52      0.61       750\n",
      "           3       0.55      0.44      0.49       750\n",
      "           4       0.58      0.95      0.72       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.68      0.66      0.65      3000\n",
      "weighted avg       0.68      0.66      0.65      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 100\n",
    "epochs = 10\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(num_tokens, embedding_dim, input_length=max_length)\n",
    "embedding_layer.build()\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "x = embedding_layer(inputs)\n",
    "# Adding Bidirectional LSTM layers\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\", dtype=None\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = \"checkpoint_model_bi_lstm_64.keras\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_vector,\n",
    "    y_train_labeled,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test_vector, y_test_labeled),\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "y_pred_inverse = one_hot_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhizhouhuang/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m2,000,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,085,196</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,085,196\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,085,196</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,085,196\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhizhouhuang/Desktop/Labeled-Unreliable-News/venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 20 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 495ms/step - accuracy: 0.9995 - f1_score: 0.9995 - loss: 0.0014 - val_accuracy: 0.6327 - val_f1_score: 0.6214 - val_loss: 2.4057\n",
      "Epoch 2/2\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 500ms/step - accuracy: 0.9999 - f1_score: 0.9999 - loss: 3.0617e-04 - val_accuracy: 0.6317 - val_f1_score: 0.6139 - val_loss: 2.5912\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.77      0.82       750\n",
      "           2       0.72      0.45      0.56       750\n",
      "           3       0.46      0.38      0.42       750\n",
      "           4       0.56      0.93      0.70       750\n",
      "\n",
      "    accuracy                           0.63      3000\n",
      "   macro avg       0.65      0.63      0.62      3000\n",
      "weighted avg       0.65      0.63      0.62      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 100\n",
    "epochs = 10\n",
    "print(max_length)\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(num_tokens, embedding_dim, input_length=max_length)\n",
    "embedding_layer.build()\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "# Adding Bidirectional LSTM layers\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(32, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\", dtype=None\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "checkpoint_filepath = \"checkpoint_model_bi_lstm_64.keras\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_vector,\n",
    "    y_train_labeled,\n",
    "    epochs=2,\n",
    "    validation_data=(X_test_vector, y_test_labeled),\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "y_pred_inverse = one_hot_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m2,000,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m34,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,061,292</span> (7.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,061,292\u001b[0m (7.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,061,292</span> (7.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,061,292\u001b[0m (7.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 453ms/step - accuracy: 0.7535 - f1_score: 0.7320 - loss: 0.6275 - val_accuracy: 0.5893 - val_f1_score: 0.5727 - val_loss: 1.6249\n",
      "Epoch 2/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 455ms/step - accuracy: 0.9603 - f1_score: 0.9569 - loss: 0.1339 - val_accuracy: 0.5920 - val_f1_score: 0.5788 - val_loss: 1.5544\n",
      "Epoch 3/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 454ms/step - accuracy: 0.9833 - f1_score: 0.9819 - loss: 0.0619 - val_accuracy: 0.5637 - val_f1_score: 0.5523 - val_loss: 2.1609\n",
      "Epoch 4/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 451ms/step - accuracy: 0.9911 - f1_score: 0.9904 - loss: 0.0367 - val_accuracy: 0.6253 - val_f1_score: 0.6178 - val_loss: 2.2977\n",
      "Epoch 5/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 461ms/step - accuracy: 0.9949 - f1_score: 0.9945 - loss: 0.0207 - val_accuracy: 0.6283 - val_f1_score: 0.6171 - val_loss: 2.5565\n",
      "Epoch 6/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m709s\u001b[0m 465ms/step - accuracy: 0.9960 - f1_score: 0.9957 - loss: 0.0159 - val_accuracy: 0.6500 - val_f1_score: 0.6408 - val_loss: 3.3576\n",
      "Epoch 7/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 455ms/step - accuracy: 0.9967 - f1_score: 0.9965 - loss: 0.0134 - val_accuracy: 0.6610 - val_f1_score: 0.6486 - val_loss: 2.8148\n",
      "Epoch 8/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 458ms/step - accuracy: 0.9987 - f1_score: 0.9987 - loss: 0.0073 - val_accuracy: 0.6753 - val_f1_score: 0.6664 - val_loss: 2.8948\n",
      "Epoch 9/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 455ms/step - accuracy: 0.9976 - f1_score: 0.9974 - loss: 0.0095 - val_accuracy: 0.6437 - val_f1_score: 0.6359 - val_loss: 3.7167\n",
      "Epoch 10/10\n",
      "\u001b[1m1527/1527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 454ms/step - accuracy: 0.9990 - f1_score: 0.9989 - loss: 0.0054 - val_accuracy: 0.6420 - val_f1_score: 0.6334 - val_loss: 3.4145\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.79      0.82       750\n",
      "           2       0.80      0.56      0.66       750\n",
      "           3       0.55      0.41      0.47       750\n",
      "           4       0.58      0.94      0.71       750\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.70      0.68      0.67      3000\n",
      "weighted avg       0.70      0.68      0.67      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 100\n",
    "epochs = 10\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(num_tokens, embedding_dim, input_length=max_length)\n",
    "embedding_layer.build()\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "x = embedding_layer(inputs)\n",
    "# Adding Bidirectional LSTM layers\n",
    "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(32))(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.F1Score(\n",
    "            average=\"macro\", threshold=None, name=\"f1_score\", dtype=None\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_filepath = \"checkpoint_model_bi_lstm_64_2.keras\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_vector,\n",
    "    y_train_labeled,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test_vector, y_test_labeled),\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "y_pred_inverse = one_hot_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred_inverse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
